{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on Amazon food reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required Modules\n",
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanpunc(sentence): \n",
    "    '''\n",
    "    function to clean the word of any punctuation or special characters\n",
    "    '''\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "def cleanhtml(sentence): \n",
    "    '''\n",
    "    function to clean the word of any html-tags\n",
    "    '''\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.remove('not')\n",
    "stop.remove('very')\n",
    "#from autocorrect import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('final_clean_LR.sqlite')\n",
    "final_review = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews_final\n",
    "\"\"\", conn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = final_review.sample(n=30000,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SORT by time for TBS\n",
    "s = s.sort_values(by='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 431 to 339792\n",
      "Data columns (total 15 columns):\n",
      "level_0                   30000 non-null int64\n",
      "index                     30000 non-null int64\n",
      "Id                        30000 non-null int64\n",
      "ProductId                 30000 non-null object\n",
      "UserId                    30000 non-null object\n",
      "ProfileName               30000 non-null object\n",
      "HelpfulnessNumerator      30000 non-null int64\n",
      "HelpfulnessDenominator    30000 non-null int64\n",
      "Score                     30000 non-null object\n",
      "Time                      30000 non-null int64\n",
      "Summary                   30000 non-null object\n",
      "Text                      30000 non-null object\n",
      "CleanedTextBow            30000 non-null object\n",
      "final_text                30000 non-null object\n",
      "final_stem_text           30000 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "s.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing lables to 1 or 0\n",
    "s.Score = final_review.Score.apply(lambda x:\n",
    "                     1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to int8\n",
    "s.HelpfulnessNumerator = s.HelpfulnessNumerator.astype(np.int8)\n",
    "s.HelpfulnessDenominator = s.HelpfulnessDenominator.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Dataframe for train and test\n",
    "train_df = s.iloc[:round(s.shape[0]*0.70),:]\n",
    "test_df = s.iloc[round(s.shape[0]*0.70):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_svm.csv',index=False)\n",
    "test_df.to_csv('test_df_svm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 15)\n",
      "(9000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW with cleaned data and without stopwords\n",
    "#simple cv for train data\n",
    "scores_train = []\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.remove('not')\n",
    "stop.remove('very')\n",
    "#CountVectorizer for BoW\n",
    "count_vect = CountVectorizer(stop_words=list(stop),dtype=np.int8)\n",
    "X_train = train_df.iloc[:round(train_df.shape[0]*0.70),:]\n",
    "X_test_cv = train_df.iloc[round(train_df.shape[0]*0.70):,:]\n",
    "final_counts_train = count_vect.fit_transform(\n",
    "        X_train['final_text'].values)\n",
    "#test\n",
    "X_test = count_vect.transform(X_test_cv['final_text'].values)\n",
    "\n",
    "scale =StandardScaler(with_mean=False)\n",
    "X_train_scale = scale.fit_transform(final_counts_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.001 Gamma 0.01 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.001 Gamma 0.001 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.001 Gamma 0.1 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.001 Gamma 1 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.01 Gamma 0.01 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.01 Gamma 0.001 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.01 Gamma 0.1 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.01 Gamma 1 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.1 Gamma 0.01 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.1 Gamma 0.001 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.1 Gamma 0.1 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 0.1 Gamma 1 Train Score 0.8605306122448979 Test Score 0.8275238095238096\n",
      "C 1 Gamma 0.01 Train Score 0.9997959183673469 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.001 Train Score 0.9951700680272109 Test Score 0.8274603174603175\n",
      "C 1 Gamma 0.1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 1 Gamma 1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 10 Gamma 0.01 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 10 Gamma 0.001 Train Score 1.0 Test Score 0.8312698412698413\n",
      "C 10 Gamma 0.1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 10 Gamma 1 Train Score 1.0 Test Score 0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'C':[0.001, 0.01, 0.1, 1, 10],\n",
    "                    'gamma':[0.01, 0.001, 0.1, 1]}):\n",
    "    model = SVC(C=i['C'],kernel='rbf',gamma=i['gamma'])\n",
    "    model.fit(X_train_scale,X_train.Score)\n",
    "    train_score = model.score(X_train_scale,X_train.Score)\n",
    "    test_score = model.score(X_test,X_test_cv.Score)\n",
    "    print('C',i['C'],'Gamma',i['gamma'],'Train Score',train_score,\n",
    "                     'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.2 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.2 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.2 Gamma 0.0001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.2 Gamma 0.005 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.5 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.5 Gamma 0.001 Train Score 0.8568707482993198 Test Score 0.8253968253968254\n",
      "C 0.5 Gamma 0.0001 Train Score 0.8601360544217687 Test Score 0.8271428571428572\n",
      "C 0.5 Gamma 0.005 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.8 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.8 Gamma 0.001 Train Score 0.8745578231292517 Test Score 0.8265079365079365\n",
      "C 0.8 Gamma 0.0001 Train Score 0.9240136054421769 Test Score 0.8353968253968254\n",
      "C 0.8 Gamma 0.005 Train Score 0.8566666666666667 Test Score 0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'C':[0.2,0.5,0.8],\n",
    "                    'gamma':[0.01, 0.001, 0.0001, 0.005]}):\n",
    "    model = SVC(C=i['C'],kernel='rbf',gamma=i['gamma'])\n",
    "    model.fit(X_train_scale,X_train.Score)\n",
    "    train_score = model.score(X_train_scale,X_train.Score)\n",
    "    test_score = model.score(X_test,X_test_cv.Score)\n",
    "    print('C',i['C'],'Gamma',i['gamma'],'Train Score',train_score,\n",
    "                     'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed that for high C- training data is overfitting so much. for low c.  and low values of gamma is giving somewat better scores than high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0.005,0.01,0.4,0.8,1.2]\n",
    "gamma = [0.000009,0.0008,0.001,0.04,0.2,5,10,15]\n",
    "model_grid_bow = GridSearchCV(make_pipeline(CountVectorizer(stop_words=list(stop)),\n",
    "                                            StandardScaler(with_mean=False),SVC()),\n",
    "                             param_grid={'svc__C': c,'svc__gamma':gamma},\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_grid_bow.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_bow.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_bow.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.845207</td>\n",
       "      <td>0.019683</td>\n",
       "      <td>0.995821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.844159</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>0.996686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.200</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.020834</td>\n",
       "      <td>0.883865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.843269</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.883656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.842902</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>0.880644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.842378</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.869664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.842326</td>\n",
       "      <td>0.021650</td>\n",
       "      <td>0.869558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021703</td>\n",
       "      <td>0.871792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gamma      C  Test_score  Test_std  Train_score\n",
       "33   0.000800  1.200    0.845207  0.019683     0.995821\n",
       "34   0.001000  1.200    0.844159  0.020326     0.996686\n",
       "32   0.000009  1.200    0.843478  0.020834     0.883865\n",
       "25   0.000800  0.800    0.843269  0.021011     0.883656\n",
       "26   0.001000  0.800    0.842902  0.021275     0.880644\n",
       "17   0.000800  0.400    0.842378  0.021622     0.869664\n",
       "18   0.001000  0.400    0.842326  0.021650     0.869558\n",
       "0    0.000009  0.005    0.842273  0.021690     0.869488\n",
       "28   0.200000  0.800    0.842273  0.021690     0.869498\n",
       "23  15.000000  0.400    0.842273  0.021690     0.869488\n",
       "24   0.000009  0.800    0.842273  0.021703     0.871792\n",
       "27   0.040000  0.800    0.842273  0.021690     0.869498\n",
       "30  10.000000  0.800    0.842273  0.021690     0.869498\n",
       "29   5.000000  0.800    0.842273  0.021690     0.869498\n",
       "21   5.000000  0.400    0.842273  0.021690     0.869488"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top scores wit grid search\n",
    "scores_df.sort_values('Test_score',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomSearch\n",
    "model_random_bow = RandomizedSearchCV(\n",
    "                    make_pipeline(CountVectorizer(stop_words=list(stop)),\n",
    "                    StandardScaler(with_mean=False),SVC()),\n",
    "                    param_distributions={'svc__C': uniform(loc=0,scale=0.7),\n",
    "                        'svc__gamma':uniform(loc=0,scale=0.01)},n_iter=15,\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_random_bow.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_bow.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_bow.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df1 = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.473474</td>\n",
       "      <td>0.842850</td>\n",
       "      <td>0.021271</td>\n",
       "      <td>0.870966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.545602</td>\n",
       "      <td>0.842378</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.870091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.237241</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.257014</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.182690</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.527309</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.325648</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.498052</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.151355</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.141517</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         C  Test_score  Test_std  Train_score\n",
       "4   0.000415  0.473474    0.842850  0.021271     0.870966\n",
       "14  0.001121  0.545602    0.842378  0.021622     0.870091\n",
       "0   0.006791  0.237241    0.842273  0.021690     0.869488\n",
       "1   0.004997  0.257014    0.842273  0.021690     0.869488\n",
       "2   0.005213  0.182690    0.842273  0.021690     0.869488\n",
       "3   0.007353  0.527309    0.842273  0.021690     0.869498\n",
       "5   0.003778  0.325648    0.842273  0.021690     0.869488\n",
       "6   0.001744  0.498052    0.842273  0.021690     0.869552\n",
       "7   0.003124  0.151355    0.842273  0.021690     0.869488\n",
       "8   0.006712  0.141517    0.842273  0.021690     0.869488"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df1.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like for high C values, it is giving somewhat better cv score but it is overfitting so much. There is a difference of >15% in train and test scores. so found that `gamma = 0.000800 C = 0.400` are the better params with cv score of\t`0.842378`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW with cleaned data and without stopwords and binary\n",
    "#simple cv for train data\n",
    "scores_train = []\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.remove('not')\n",
    "stop.remove('very')\n",
    "#CountVectorizer for BoW\n",
    "count_vect = CountVectorizer(stop_words=list(stop),binary=True,dtype=np.int8)\n",
    "X_train = train_df.iloc[:round(train_df.shape[0]*0.70),:]\n",
    "X_test_cv = train_df.iloc[round(train_df.shape[0]*0.70):,:]\n",
    "final_counts_train = count_vect.fit_transform(\n",
    "        X_train['final_text'].values)\n",
    "#test\n",
    "X_test = count_vect.transform(X_test_cv['final_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.4 Gamma 0.0008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.4 Gamma 0.005 Train Score 0.8725850340136054 Test Score 0.840952380952381\n",
      "C 0.4 Gamma 0.1 Train Score 0.8656462585034014 Test Score 0.8284126984126984\n",
      "C 0.4 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.8 Gamma 0.0008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.8 Gamma 0.005 Train Score 0.9155102040816326 Test Score 0.8819047619047619\n",
      "C 0.8 Gamma 0.1 Train Score 0.9710884353741497 Test Score 0.8444444444444444\n",
      "C 0.8 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.0008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.005 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.0008 Train Score 0.8570748299319728 Test Score 0.8257142857142857\n",
      "C 1 Gamma 0.005 Train Score 0.9269387755102041 Test Score 0.8920634920634921\n",
      "C 1 Gamma 0.1 Train Score 0.9973469387755102 Test Score 0.8485714285714285\n",
      "C 1 Gamma 1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 10 Gamma 0.0008 Train Score 0.9442857142857143 Test Score 0.9082539682539682\n",
      "C 10 Gamma 0.005 Train Score 0.9850340136054422 Test Score 0.92\n",
      "C 10 Gamma 0.1 Train Score 1.0 Test Score 0.8571428571428571\n",
      "C 10 Gamma 1 Train Score 1.0 Test Score 0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'C':[0.4, 0.8, 0.1, 1, 10],\n",
    "                    'gamma':[0.0008,0.005, 0.1, 1]}):\n",
    "    model = SVC(C=i['C'],kernel='rbf',gamma=i['gamma'])\n",
    "    model.fit(final_counts_train,X_train.Score)\n",
    "    train_score = model.score(final_counts_train,X_train.Score)\n",
    "    test_score = model.score(X_test,X_test_cv.Score)\n",
    "    print('C',i['C'],'Gamma',i['gamma'],'Train Score',train_score,\n",
    "                     'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried with binary Count vectorizer and found some interesting results with high accuracy for gamma in range of 0.001-0.01 and and c > 0.8, i am getting some high test scores for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0.8,0.9,1,1.5,3,5,7,10]\n",
    "gamma = [0.0008,0.001,0.003,0.005,0.008,0.01,0.05,0.08]\n",
    "model_grid_bow_binary = GridSearchCV(make_pipeline(CountVectorizer(stop_words=list(stop),binary=True),\n",
    "                                            SVC()),\n",
    "                             param_grid={'svc__C': c,'svc__gamma':gamma},\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_grid_bow_binary.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_bow_binary.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_bow_binary.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df_bin = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.010</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.921215</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>0.993688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.920639</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.996447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.920377</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.989241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.920063</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.994219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.008</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.920010</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.990022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.919329</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.986794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.008</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.919068</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.984562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.005</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.918649</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.980237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.003</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.917444</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.975592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.916763</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.979108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gamma     C  Test_score  Test_std  Train_score\n",
       "53  0.010   7.0    0.921215  0.005992     0.993688\n",
       "61  0.010  10.0    0.920639  0.005565     0.996447\n",
       "45  0.010   5.0    0.920377  0.006399     0.989241\n",
       "60  0.008  10.0    0.920063  0.005074     0.994219\n",
       "52  0.008   7.0    0.920010  0.005494     0.990022\n",
       "59  0.005  10.0    0.919329  0.005046     0.986794\n",
       "44  0.008   5.0    0.919068  0.006339     0.984562\n",
       "51  0.005   7.0    0.918649  0.007152     0.980237\n",
       "58  0.003  10.0    0.917444  0.007297     0.975592\n",
       "37  0.010   3.0    0.916763  0.009404     0.979108"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top scores\n",
    "scores_df_bin.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random search\n",
    "model_random_bow_binary = RandomizedSearchCV(\n",
    "                    make_pipeline(CountVectorizer(stop_words=list(stop),binary=True),\n",
    "                            SVC()),\n",
    "                 param_distributions={'svc__C': uniform(loc=0,scale=10),\n",
    "                'svc__gamma':uniform(loc=0.003,scale=0.017)},n_iter=20,\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_random_bow_binary.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_bow_binary.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_bow_binary.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df1_bin = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012632</td>\n",
       "      <td>5.387201</td>\n",
       "      <td>0.921320</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.994085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010988</td>\n",
       "      <td>8.434631</td>\n",
       "      <td>0.920744</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.996239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.013324</td>\n",
       "      <td>5.211789</td>\n",
       "      <td>0.920691</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.994289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.015818</td>\n",
       "      <td>4.657298</td>\n",
       "      <td>0.920482</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.995270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008742</td>\n",
       "      <td>6.182782</td>\n",
       "      <td>0.920377</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.989817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015201</td>\n",
       "      <td>7.367153</td>\n",
       "      <td>0.920272</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.997701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017782</td>\n",
       "      <td>4.186368</td>\n",
       "      <td>0.920168</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.995562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006675</td>\n",
       "      <td>7.241270</td>\n",
       "      <td>0.919906</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.987144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018738</td>\n",
       "      <td>5.846448</td>\n",
       "      <td>0.919749</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>0.997884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015909</td>\n",
       "      <td>8.272383</td>\n",
       "      <td>0.919644</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>0.998387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         C  Test_score  Test_std  Train_score\n",
       "9   0.012632  5.387201    0.921320  0.006144     0.994085\n",
       "7   0.010988  8.434631    0.920744  0.005843     0.996239\n",
       "18  0.013324  5.211789    0.920691  0.006230     0.994289\n",
       "13  0.015818  4.657298    0.920482  0.007147     0.995270\n",
       "0   0.008742  6.182782    0.920377  0.005578     0.989817\n",
       "6   0.015201  7.367153    0.920272  0.007147     0.997701\n",
       "2   0.017782  4.186368    0.920168  0.007176     0.995562\n",
       "14  0.006675  7.241270    0.919906  0.006305     0.987144\n",
       "1   0.018738  5.846448    0.919749  0.007964     0.997884\n",
       "15  0.015909  8.272383    0.919644  0.008027     0.998387"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top scores\n",
    "scores_df1_bin.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comapared to Non-binary Bag of word binary bag of words score was high and best score found at `gamma = 0.010 ,C = 7.0` and cv mean score is 0.921215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 7 gamma 0.01\n",
      "Train Score 0.9915238095238095\n",
      "Test Score 0.9246666666666666\n",
      "Test Precision 0.9447222953408791\n",
      "Test Recall 0.9653039268423884\n",
      "Test ConfusionMatrix [[1144  420]\n",
      " [ 258 7178]]\n"
     ]
    }
   ],
   "source": [
    "#test scores\n",
    "scores_train = []\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.remove('not')\n",
    "stop.remove('very')\n",
    "#CountVectorizer for BoW\n",
    "count_vect = CountVectorizer(stop_words=list(stop),binary=True,dtype=np.int8)\n",
    "final_counts_train = count_vect.fit_transform(\n",
    "        train_df['final_text'].values)\n",
    "#test\n",
    "X_test = count_vect.transform(test_df['final_text'].values)\n",
    "\n",
    "model = SVC(C=7,kernel='rbf',gamma=0.010)\n",
    "model.fit(final_counts_train,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(final_counts_train)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print('C' ,7,'gamma',0.010)\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2245, 3591], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no of support vectrors for each class\n",
    "model.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD With BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random search\n",
    "model_random_bow_binary = RandomizedSearchCV(make_pipeline(\n",
    "                              CountVectorizer(stop_words=list(stop),binary=True),\n",
    "                               SGDClassifier(n_jobs=-1)),\n",
    "                     param_distributions={'sgdclassifier__penalty':['l1','l2'],\n",
    "                        'sgdclassifier__alpha':uniform(loc=0.00001,scale=0.069),\n",
    "                        'sgdclassifier__l1_ratio':uniform(loc=0,scale=1)},\n",
    "                                                n_iter=100,\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_random_bow_binary.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_bow_binary.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['sgdclassifier__alpha'])\n",
    "    dict_score.append(i[0]['sgdclassifier__l1_ratio'])\n",
    "    dict_score.append(i[0]['sgdclassifier__penalty'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_bow_binary.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df1_bin = pd.DataFrame(dict_scores,columns=['alpha','l1_rato','penality','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_rato</th>\n",
       "      <th>penality</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.912537</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.915977</td>\n",
       "      <td>0.007592</td>\n",
       "      <td>0.961918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.544642</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.915872</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.980992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.797285</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.910529</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.983756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.314634</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.906129</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.946527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.760320</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.901414</td>\n",
       "      <td>0.010897</td>\n",
       "      <td>0.937890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.744540</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.900681</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.962679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.273312</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.900210</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.935924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.480412</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.898638</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>0.934297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.611535</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.893557</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.928721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.015297</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.892981</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.926446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha   l1_rato penality  Test_score  Test_std  Train_score\n",
       "13  0.003570  0.912537       l2    0.915977  0.007592     0.961918\n",
       "95  0.000654  0.544642       l2    0.915872  0.006177     0.980992\n",
       "38  0.000256  0.797285       l2    0.910529  0.006600     0.983756\n",
       "46  0.007463  0.314634       l2    0.906129  0.010484     0.946527\n",
       "80  0.010533  0.760320       l2    0.901414  0.010897     0.937890\n",
       "7   0.000199  0.744540       l1    0.900681  0.006887     0.962679\n",
       "63  0.011535  0.273312       l2    0.900210  0.011199     0.935924\n",
       "56  0.012332  0.480412       l2    0.898638  0.010939     0.934297\n",
       "22  0.013868  0.611535       l2    0.893557  0.009607     0.928721\n",
       "77  0.015297  0.045345       l2    0.892981  0.011083     0.926446"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df1_bin.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got best mean cv at alpha = 0.003570. l1_ratio = 0.912537 and penality l2 and corresponding mean cv test score is 0.915977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With SGD Classifier penalty='l2',alpha=0.003570,l1_ratio=0.912537 \n",
      "Train Score 0.9445238095238095\n",
      "Test Score 0.9197777777777778\n",
      "Test Precision 0.930053804765565\n",
      "Test Recall 0.9763313609467456\n",
      "Test ConfusionMatrix [[1018  546]\n",
      " [ 176 7260]]\n"
     ]
    }
   ],
   "source": [
    "#test scores\n",
    "scores_train = []\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.remove('not')\n",
    "stop.remove('very')\n",
    "#CountVectorizer for BoW\n",
    "count_vect = CountVectorizer(stop_words=list(stop),binary=True,dtype=np.int8)\n",
    "final_counts_train = count_vect.fit_transform(\n",
    "        train_df['final_text'].values)\n",
    "#test\n",
    "X_test = count_vect.transform(test_df['final_text'].values)\n",
    "\n",
    "model = SGDClassifier(penalty='l2',alpha=0.003570,l1_ratio=0.912537,n_jobs=-1) #0.003570\t0.912537\tl2\t\n",
    "model.fit(final_counts_train,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(final_counts_train)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print(\"With SGD Classifier penalty='l2',alpha=0.003570,l1_ratio=0.912537 \")\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF with (1,2) gram with cleaned data \n",
    "#simple cv for train data\n",
    "#tfidf vec \n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "X_train = train_df.iloc[:round(train_df.shape[0]*0.70),:]\n",
    "X_test_cv = train_df.iloc[round(train_df.shape[0]*0.70):,:]\n",
    "final_counts_train = tf_idf_vect.fit_transform(\n",
    "        X_train['final_text'].values)\n",
    "#test\n",
    "X_test = tf_idf_vect.transform(X_test_cv['final_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.001 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.1 Train Score 0.8623129251700681 Test Score 0.8311111111111111\n",
      "C 1 Gamma 0.5 Train Score 0.978843537414966 Test Score 0.9011111111111111\n",
      "C 1 Gamma 1 Train Score 0.9975510204081632 Test Score 0.8942857142857142\n",
      "C 1 Gamma 10 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 5 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 5 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 5 Gamma 0.01 Train Score 0.8564625850340136 Test Score 0.8253968253968254\n",
      "C 5 Gamma 0.1 Train Score 0.9954421768707483 Test Score 0.9288888888888889\n",
      "C 5 Gamma 0.5 Train Score 1.0 Test Score 0.93\n",
      "C 5 Gamma 1 Train Score 1.0 Test Score 0.9146031746031746\n",
      "C 5 Gamma 10 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 10 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 10 Gamma 0.008 Train Score 0.8604081632653061 Test Score 0.8293650793650794\n",
      "C 10 Gamma 0.01 Train Score 0.8687074829931973 Test Score 0.8380952380952381\n",
      "C 10 Gamma 0.1 Train Score 0.9999319727891156 Test Score 0.9382539682539682\n",
      "C 10 Gamma 0.5 Train Score 1.0 Test Score 0.93\n",
      "C 10 Gamma 1 Train Score 1.0 Test Score 0.9146031746031746\n",
      "C 10 Gamma 10 Train Score 1.0 Test Score 0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'C':[0.001,0.01,0.1,1,5,10],\n",
    "                    'gamma':[0.001,0.008,0.01,0.1,0.5,1,10]}):\n",
    "    model = SVC(C=i['C'],kernel='rbf',gamma=i['gamma'])\n",
    "    model.fit(final_counts_train,X_train.Score)\n",
    "    train_score = model.score(final_counts_train,X_train.Score)\n",
    "    test_score = model.score(X_test,X_test_cv.Score)\n",
    "    print('C',i['C'],'Gamma',i['gamma'],'Train Score',train_score,\n",
    "                     'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0.1,0.5,0.8,1,5,7,10,20]\n",
    "gamma = [0.008,0.007,0.1,0.3,0.5,1,3,10]\n",
    "model_grid_tfidf = GridSearchCV(make_pipeline(TfidfVectorizer(ngram_range=(1,2)),\n",
    "                                            SVC()),\n",
    "                             param_grid={'svc__C': c,'svc__gamma':gamma},\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_grid_tfidf.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_tfidf.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_tfidf.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.925982</td>\n",
       "      <td>0.013537</td>\n",
       "      <td>0.999961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.925930</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.922263</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.999523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.922263</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.922211</td>\n",
       "      <td>0.014668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.922211</td>\n",
       "      <td>0.014668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.922211</td>\n",
       "      <td>0.014668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gamma     C  Test_score  Test_std  Train_score\n",
       "50    0.1  10.0    0.925982  0.013537     0.999961\n",
       "58    0.1  20.0    0.925930  0.013911     1.000000\n",
       "42    0.1   7.0    0.922263  0.014279     0.999523\n",
       "35    0.3   5.0    0.922263  0.014587     1.000000\n",
       "51    0.3  10.0    0.922211  0.014668     1.000000\n",
       "43    0.3   7.0    0.922211  0.014668     1.000000\n",
       "59    0.3  20.0    0.922211  0.014668     1.000000\n",
       "36    0.5   5.0    0.918806  0.014783     1.000000\n",
       "52    0.5  10.0    0.918806  0.014783     1.000000\n",
       "44    0.5   7.0    0.918806  0.014783     1.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for high values of c model is overfitting to train data and for each c with reasonable gamma is giving good score than low or high gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random_tfidf = RandomizedSearchCV(\n",
    "                      make_pipeline(TfidfVectorizer(ngram_range=(1,2)),SVC()),\n",
    "                      param_distributions={'svc__C':uniform(loc=0,scale=12),\n",
    "                                       'svc__gamma':uniform(loc=0,scale=0.7)},\n",
    "                            n_iter=20,cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_random_tfidf.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_tfidf.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_tfidf.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df1 = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.175194</td>\n",
       "      <td>7.107109</td>\n",
       "      <td>0.924987</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205345</td>\n",
       "      <td>7.555669</td>\n",
       "      <td>0.924620</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.192857</td>\n",
       "      <td>4.893355</td>\n",
       "      <td>0.923258</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.266751</td>\n",
       "      <td>8.332227</td>\n",
       "      <td>0.923206</td>\n",
       "      <td>0.014551</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.324423</td>\n",
       "      <td>5.865958</td>\n",
       "      <td>0.922001</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.311839</td>\n",
       "      <td>10.320605</td>\n",
       "      <td>0.921896</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.273510</td>\n",
       "      <td>3.244258</td>\n",
       "      <td>0.921320</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.999898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.347285</td>\n",
       "      <td>9.050680</td>\n",
       "      <td>0.921163</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.430498</td>\n",
       "      <td>11.934278</td>\n",
       "      <td>0.920430</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.068950</td>\n",
       "      <td>8.277344</td>\n",
       "      <td>0.919958</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.998265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma          C  Test_score  Test_std  Train_score\n",
       "13  0.175194   7.107109    0.924987  0.014313     1.000000\n",
       "4   0.205345   7.555669    0.924620  0.014065     1.000000\n",
       "0   0.192857   4.893355    0.923258  0.014181     0.999950\n",
       "8   0.266751   8.332227    0.923206  0.014551     1.000000\n",
       "11  0.324423   5.865958    0.922001  0.014653     1.000000\n",
       "15  0.311839  10.320605    0.921896  0.014627     1.000000\n",
       "18  0.273510   3.244258    0.921320  0.014689     0.999898\n",
       "19  0.347285   9.050680    0.921163  0.014763     1.000000\n",
       "6   0.430498  11.934278    0.920430  0.014574     1.000000\n",
       "14  0.068950   8.277344    0.919958  0.015449     0.998265"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top scores with random search\n",
    "scores_df1.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 10 fold cv got high mean cv at `gamma  = 0.175194, C = 7.107109` and mean cv is 0.924987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 7 gamma 0.175194\n",
      "Train Score 1.0\n",
      "Test Score 0.9415555555555556\n",
      "Test Precision 0.9508089770354906\n",
      "Test Recall 0.9799623453469607\n",
      "Test ConfusionMatrix [[1187  377]\n",
      " [ 149 7287]]\n",
      "No of support vectors for each class [2810 6720]\n"
     ]
    }
   ],
   "source": [
    "#test scores\n",
    "#TFIDF with (1,2) gram with cleaned data \n",
    "#tfidf vec \n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_counts_train = tf_idf_vect.fit_transform(\n",
    "        train_df['final_text'].values)\n",
    "#test\n",
    "X_test = tf_idf_vect.transform(test_df['final_text'].values)\n",
    "\n",
    "model = SVC(C=7.107109,kernel='rbf',gamma=0.175194)\n",
    "model.fit(final_counts_train,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(final_counts_train)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print('C' ,7,'gamma',0.175194)\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)\n",
    "print('No of support vectors for each class',model.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random_tfidf = RandomizedSearchCV(make_pipeline(TfidfVectorizer(ngram_range=(1,2)),\n",
    "                                            SGDClassifier(n_jobs=-1)),\n",
    "                             param_distributions={'sgdclassifier__penalty':['l1','l2'],\n",
    "                                'sgdclassifier__alpha':uniform(loc=0.00001,scale=0.069),\n",
    "                                  'sgdclassifier__l1_ratio':uniform(loc=0,scale=1)},n_iter=300\n",
    "                                        ,cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_random_tfidf.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_tfidf.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['sgdclassifier__alpha'])\n",
    "    dict_score.append(i[0]['sgdclassifier__l1_ratio'])\n",
    "    dict_score.append(i[0]['sgdclassifier__penalty'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_tfidf.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df1 = pd.DataFrame(dict_scores,columns=['alpha','l1_ratio','penality','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>penality</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.738118</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.912729</td>\n",
       "      <td>0.007599</td>\n",
       "      <td>0.983543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.550213</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.878104</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.935960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.305034</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.019746</td>\n",
       "      <td>0.925270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.538170</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.865008</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.885320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.431934</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.847564</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.886908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.509713</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.843426</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>0.879669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.546427</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.842326</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>0.873685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.990595</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.025632</td>\n",
       "      <td>0.245308</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.016020</td>\n",
       "      <td>0.509449</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.842273</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>0.869488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha  l1_ratio penality  Test_score  Test_std  Train_score\n",
       "206  0.000116  0.738118       l2    0.912729  0.007599     0.983543\n",
       "263  0.000233  0.550213       l2    0.878104  0.017691     0.935960\n",
       "153  0.000264  0.305034       l2    0.870875  0.019746     0.925270\n",
       "184  0.000207  0.538170       l1    0.865008  0.015358     0.885320\n",
       "29   0.000437  0.431934       l2    0.847564  0.023918     0.886908\n",
       "268  0.000545  0.509713       l2    0.843426  0.022213     0.879669\n",
       "179  0.000690  0.546427       l2    0.842326  0.021736     0.873685\n",
       "202  0.043333  0.990595       l1    0.842273  0.021690     0.869488\n",
       "201  0.025632  0.245308       l1    0.842273  0.021690     0.869488\n",
       "200  0.016020  0.509449       l1    0.842273  0.021690     0.869488"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df1.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 5e-05 l1_ratio 0 Penality l1 Train Score 0.9470748299319728 Test Score 0.9303174603174603\n",
      "Alpha 5e-05 l1_ratio 0 Penality l2 Train Score 0.998639455782313 Test Score 0.9344444444444444\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality l1 Train Score 0.9455102040816327 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality l2 Train Score 0.9984353741496599 Test Score 0.9350793650793651\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality l1 Train Score 0.9473469387755102 Test Score 0.9280952380952381\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality l2 Train Score 0.9985034013605442 Test Score 0.9350793650793651\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality l1 Train Score 0.9428571428571428 Test Score 0.9244444444444444\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality l2 Train Score 0.998639455782313 Test Score 0.9326984126984127\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality l1 Train Score 0.9444897959183673 Test Score 0.9287301587301587\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality l2 Train Score 0.998639455782313 Test Score 0.9357142857142857\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality l1 Train Score 0.9457142857142857 Test Score 0.9271428571428572\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality l2 Train Score 0.9985714285714286 Test Score 0.933968253968254\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality l1 Train Score 0.9439455782312925 Test Score 0.9246031746031746\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality l2 Train Score 0.9985714285714286 Test Score 0.9355555555555556\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality l1 Train Score 0.9451020408163265 Test Score 0.9257142857142857\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality l2 Train Score 0.9983673469387755 Test Score 0.9328571428571428\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality l1 Train Score 0.9470748299319728 Test Score 0.9284126984126985\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality l2 Train Score 0.998639455782313 Test Score 0.9368253968253968\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality l1 Train Score 0.9471428571428572 Test Score 0.9295238095238095\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality l2 Train Score 0.998639455782313 Test Score 0.9350793650793651\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality l1 Train Score 0.9452380952380952 Test Score 0.9266666666666666\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality l2 Train Score 0.9983673469387755 Test Score 0.9325396825396826\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality l1 Train Score 0.9455102040816327 Test Score 0.9265079365079365\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality l2 Train Score 0.9984353741496599 Test Score 0.9358730158730159\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality l1 Train Score 0.947687074829932 Test Score 0.9298412698412698\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality l2 Train Score 0.9985034013605442 Test Score 0.9336507936507936\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality l1 Train Score 0.9448979591836735 Test Score 0.9252380952380952\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality l2 Train Score 0.9985714285714286 Test Score 0.936984126984127\n",
      "Alpha 8e-05 l1_ratio 0 Penality l1 Train Score 0.9295918367346939 Test Score 0.9147619047619048\n",
      "Alpha 8e-05 l1_ratio 0 Penality l2 Train Score 0.9891836734693877 Test Score 0.9268253968253968\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality l1 Train Score 0.9272789115646258 Test Score 0.9141269841269841\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality l2 Train Score 0.9894557823129252 Test Score 0.926984126984127\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality l1 Train Score 0.9251700680272109 Test Score 0.9125396825396825\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality l2 Train Score 0.9907482993197279 Test Score 0.9280952380952381\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality l1 Train Score 0.9274829931972789 Test Score 0.9130158730158731\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality l2 Train Score 0.9907482993197279 Test Score 0.927936507936508\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality l1 Train Score 0.9248979591836735 Test Score 0.913968253968254\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality l2 Train Score 0.988843537414966 Test Score 0.9247619047619048\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality l1 Train Score 0.9279591836734694 Test Score 0.9128571428571428\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality l2 Train Score 0.988843537414966 Test Score 0.9255555555555556\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality l1 Train Score 0.9262585034013605 Test Score 0.9096825396825396\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality l2 Train Score 0.9885034013605443 Test Score 0.9266666666666666\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality l1 Train Score 0.9283673469387755 Test Score 0.9153968253968254\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality l2 Train Score 0.9893877551020408 Test Score 0.926031746031746\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality l1 Train Score 0.9261224489795918 Test Score 0.9114285714285715\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality l2 Train Score 0.9889795918367347 Test Score 0.9247619047619048\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality l1 Train Score 0.9268027210884354 Test Score 0.9123809523809524\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality l2 Train Score 0.9903401360544217 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality l1 Train Score 0.9248979591836735 Test Score 0.9084126984126984\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality l2 Train Score 0.9908163265306122 Test Score 0.9293650793650794\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality l1 Train Score 0.9285034013605442 Test Score 0.9136507936507936\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality l2 Train Score 0.9907482993197279 Test Score 0.9287301587301587\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality l1 Train Score 0.926734693877551 Test Score 0.9125396825396825\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality l2 Train Score 0.9890476190476191 Test Score 0.9249206349206349\n",
      "Alpha 8e-05 l1_ratio 0.95 Penality l1 Train Score 0.9276190476190476 Test Score 0.9119047619047619\n",
      "Alpha 8e-05 l1_ratio 0.95 Penality l2 Train Score 0.991156462585034 Test Score 0.93\n",
      "Alpha 0.0001 l1_ratio 0 Penality l1 Train Score 0.9206122448979592 Test Score 0.9082539682539682\n",
      "Alpha 0.0001 l1_ratio 0 Penality l2 Train Score 0.976326530612245 Test Score 0.9174603174603174\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality l1 Train Score 0.9180272108843538 Test Score 0.9038095238095238\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality l2 Train Score 0.9778231292517007 Test Score 0.9179365079365079\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality l1 Train Score 0.9162585034013605 Test Score 0.9028571428571428\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality l2 Train Score 0.9795918367346939 Test Score 0.9193650793650794\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality l1 Train Score 0.9176190476190477 Test Score 0.9042857142857142\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality l2 Train Score 0.9795918367346939 Test Score 0.9206349206349206\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality l1 Train Score 0.9201360544217687 Test Score 0.9066666666666666\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality l2 Train Score 0.9780952380952381 Test Score 0.9193650793650794\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality l1 Train Score 0.9177551020408163 Test Score 0.9052380952380953\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality l2 Train Score 0.9774149659863945 Test Score 0.9184126984126985\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality l1 Train Score 0.916530612244898 Test Score 0.902063492063492\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality l2 Train Score 0.9759183673469388 Test Score 0.9161904761904762\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality l1 Train Score 0.9171428571428571 Test Score 0.905079365079365\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality l2 Train Score 0.9795238095238096 Test Score 0.9215873015873016\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality l1 Train Score 0.917687074829932 Test Score 0.9047619047619048\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality l2 Train Score 0.9797959183673469 Test Score 0.9207936507936508\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality l1 Train Score 0.9180952380952381 Test Score 0.9047619047619048\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality l2 Train Score 0.98 Test Score 0.9203174603174603\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality l1 Train Score 0.9184353741496598 Test Score 0.9055555555555556\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality l2 Train Score 0.9772789115646259 Test Score 0.916984126984127\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality l1 Train Score 0.9205442176870748 Test Score 0.9071428571428571\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality l2 Train Score 0.9800680272108844 Test Score 0.922063492063492\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality l1 Train Score 0.9163945578231293 Test Score 0.9012698412698412\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality l2 Train Score 0.9791836734693877 Test Score 0.9214285714285714\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality l1 Train Score 0.9194557823129251 Test Score 0.9061904761904762\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality l2 Train Score 0.9761224489795919 Test Score 0.9180952380952381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.00012 l1_ratio 0 Penality l1 Train Score 0.9089795918367347 Test Score 0.8968253968253969\n",
      "Alpha 0.00012 l1_ratio 0 Penality l2 Train Score 0.9679591836734693 Test Score 0.9117460317460317\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality l1 Train Score 0.9079591836734694 Test Score 0.8942857142857142\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality l2 Train Score 0.9718367346938775 Test Score 0.913968253968254\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality l1 Train Score 0.9091156462585034 Test Score 0.896984126984127\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality l2 Train Score 0.9671428571428572 Test Score 0.9101587301587302\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality l1 Train Score 0.9091836734693878 Test Score 0.8949206349206349\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality l2 Train Score 0.9682312925170068 Test Score 0.912063492063492\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality l1 Train Score 0.9068707482993197 Test Score 0.8947619047619048\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality l2 Train Score 0.9696598639455782 Test Score 0.9123809523809524\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality l1 Train Score 0.9097278911564626 Test Score 0.8973015873015873\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality l2 Train Score 0.9698639455782313 Test Score 0.9144444444444444\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality l1 Train Score 0.9082993197278911 Test Score 0.895079365079365\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality l2 Train Score 0.9674829931972789 Test Score 0.9119047619047619\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality l1 Train Score 0.9074829931972789 Test Score 0.8949206349206349\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality l2 Train Score 0.969047619047619 Test Score 0.9122222222222223\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality l1 Train Score 0.9074829931972789 Test Score 0.8947619047619048\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality l2 Train Score 0.9695238095238096 Test Score 0.9131746031746032\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality l1 Train Score 0.9112925170068027 Test Score 0.8987301587301587\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality l2 Train Score 0.9710884353741497 Test Score 0.9125396825396825\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality l1 Train Score 0.9098639455782312 Test Score 0.8979365079365079\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality l2 Train Score 0.968843537414966 Test Score 0.9117460317460317\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality l1 Train Score 0.9104081632653062 Test Score 0.8977777777777778\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality l2 Train Score 0.9705442176870749 Test Score 0.9144444444444444\n",
      "Alpha 0.00012 l1_ratio 0.85 Penality l1 Train Score 0.9074149659863946 Test Score 0.895079365079365\n",
      "Alpha 0.00012 l1_ratio 0.85 Penality l2 Train Score 0.9674149659863945 Test Score 0.9111111111111111\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality l1 Train Score 0.9091836734693878 Test Score 0.8965079365079365\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality l2 Train Score 0.9676190476190476 Test Score 0.9114285714285715\n",
      "Alpha 0.00018 l1_ratio 0 Penality l1 Train Score 0.8865306122448979 Test Score 0.8715873015873016\n",
      "Alpha 0.00018 l1_ratio 0 Penality l2 Train Score 0.9310884353741496 Test Score 0.8846031746031746\n",
      "Alpha 0.00018 l1_ratio 0.03 Penality l1 Train Score 0.8848979591836734 Test Score 0.8677777777777778\n",
      "Alpha 0.00018 l1_ratio 0.03 Penality l2 Train Score 0.937891156462585 Test Score 0.8911111111111111\n",
      "Alpha 0.00018 l1_ratio 0.05 Penality l1 Train Score 0.8859183673469387 Test Score 0.8695238095238095\n",
      "Alpha 0.00018 l1_ratio 0.05 Penality l2 Train Score 0.9338095238095238 Test Score 0.8876190476190476\n",
      "Alpha 0.00018 l1_ratio 0.08 Penality l1 Train Score 0.8852380952380953 Test Score 0.8690476190476191\n",
      "Alpha 0.00018 l1_ratio 0.08 Penality l2 Train Score 0.9357823129251701 Test Score 0.8888888888888888\n",
      "Alpha 0.00018 l1_ratio 0.1 Penality l1 Train Score 0.8846938775510204 Test Score 0.8684126984126984\n",
      "Alpha 0.00018 l1_ratio 0.1 Penality l2 Train Score 0.9347619047619048 Test Score 0.888095238095238\n",
      "Alpha 0.00018 l1_ratio 0.15 Penality l1 Train Score 0.8858503401360545 Test Score 0.8707936507936508\n",
      "Alpha 0.00018 l1_ratio 0.15 Penality l2 Train Score 0.9362585034013605 Test Score 0.8911111111111111\n",
      "Alpha 0.00018 l1_ratio 0.25 Penality l1 Train Score 0.8900680272108844 Test Score 0.8741269841269841\n",
      "Alpha 0.00018 l1_ratio 0.25 Penality l2 Train Score 0.932312925170068 Test Score 0.8857142857142857\n",
      "Alpha 0.00018 l1_ratio 0.35 Penality l1 Train Score 0.8859863945578231 Test Score 0.8703174603174603\n",
      "Alpha 0.00018 l1_ratio 0.35 Penality l2 Train Score 0.9297278911564626 Test Score 0.8838095238095238\n",
      "Alpha 0.00018 l1_ratio 0.45 Penality l1 Train Score 0.8850340136054422 Test Score 0.8679365079365079\n",
      "Alpha 0.00018 l1_ratio 0.45 Penality l2 Train Score 0.9336734693877551 Test Score 0.888095238095238\n",
      "Alpha 0.00018 l1_ratio 0.55 Penality l1 Train Score 0.886734693877551 Test Score 0.871904761904762\n",
      "Alpha 0.00018 l1_ratio 0.55 Penality l2 Train Score 0.936734693877551 Test Score 0.8904761904761904\n",
      "Alpha 0.00018 l1_ratio 0.65 Penality l1 Train Score 0.8866666666666667 Test Score 0.8711111111111111\n",
      "Alpha 0.00018 l1_ratio 0.65 Penality l2 Train Score 0.9308843537414966 Test Score 0.8849206349206349\n",
      "Alpha 0.00018 l1_ratio 0.75 Penality l1 Train Score 0.8862585034013606 Test Score 0.8698412698412699\n",
      "Alpha 0.00018 l1_ratio 0.75 Penality l2 Train Score 0.934625850340136 Test Score 0.8884126984126984\n",
      "Alpha 0.00018 l1_ratio 0.85 Penality l1 Train Score 0.8873469387755102 Test Score 0.8707936507936508\n",
      "Alpha 0.00018 l1_ratio 0.85 Penality l2 Train Score 0.9358503401360544 Test Score 0.89\n",
      "Alpha 0.00018 l1_ratio 0.95 Penality l1 Train Score 0.886734693877551 Test Score 0.8715873015873016\n",
      "Alpha 0.00018 l1_ratio 0.95 Penality l2 Train Score 0.9342176870748299 Test Score 0.8879365079365079\n",
      "Alpha 0.00023 l1_ratio 0 Penality l1 Train Score 0.872312925170068 Test Score 0.8519047619047619\n",
      "Alpha 0.00023 l1_ratio 0 Penality l2 Train Score 0.9082993197278911 Test Score 0.8690476190476191\n",
      "Alpha 0.00023 l1_ratio 0.03 Penality l1 Train Score 0.8717006802721089 Test Score 0.8496825396825397\n",
      "Alpha 0.00023 l1_ratio 0.03 Penality l2 Train Score 0.9046258503401361 Test Score 0.8663492063492063\n",
      "Alpha 0.00023 l1_ratio 0.05 Penality l1 Train Score 0.8714965986394558 Test Score 0.8496825396825397\n",
      "Alpha 0.00023 l1_ratio 0.05 Penality l2 Train Score 0.9078231292517007 Test Score 0.8684126984126984\n",
      "Alpha 0.00023 l1_ratio 0.08 Penality l1 Train Score 0.8709523809523809 Test Score 0.8509523809523809\n",
      "Alpha 0.00023 l1_ratio 0.08 Penality l2 Train Score 0.9056462585034014 Test Score 0.8665079365079366\n",
      "Alpha 0.00023 l1_ratio 0.1 Penality l1 Train Score 0.867482993197279 Test Score 0.8452380952380952\n",
      "Alpha 0.00023 l1_ratio 0.1 Penality l2 Train Score 0.9051020408163265 Test Score 0.8668253968253968\n",
      "Alpha 0.00023 l1_ratio 0.15 Penality l1 Train Score 0.8693197278911564 Test Score 0.8471428571428572\n",
      "Alpha 0.00023 l1_ratio 0.15 Penality l2 Train Score 0.9060544217687074 Test Score 0.8673015873015874\n",
      "Alpha 0.00023 l1_ratio 0.25 Penality l1 Train Score 0.8701360544217687 Test Score 0.8471428571428572\n",
      "Alpha 0.00023 l1_ratio 0.25 Penality l2 Train Score 0.9053061224489796 Test Score 0.8668253968253968\n",
      "Alpha 0.00023 l1_ratio 0.35 Penality l1 Train Score 0.8735374149659864 Test Score 0.8526984126984127\n",
      "Alpha 0.00023 l1_ratio 0.35 Penality l2 Train Score 0.906734693877551 Test Score 0.8680952380952381\n",
      "Alpha 0.00023 l1_ratio 0.45 Penality l1 Train Score 0.8731972789115646 Test Score 0.8522222222222222\n",
      "Alpha 0.00023 l1_ratio 0.45 Penality l2 Train Score 0.9056462585034014 Test Score 0.8666666666666667\n",
      "Alpha 0.00023 l1_ratio 0.55 Penality l1 Train Score 0.8721088435374149 Test Score 0.8514285714285714\n",
      "Alpha 0.00023 l1_ratio 0.55 Penality l2 Train Score 0.9038095238095238 Test Score 0.8652380952380953\n",
      "Alpha 0.00023 l1_ratio 0.65 Penality l1 Train Score 0.8682312925170068 Test Score 0.8476190476190476\n",
      "Alpha 0.00023 l1_ratio 0.65 Penality l2 Train Score 0.904421768707483 Test Score 0.8661904761904762\n",
      "Alpha 0.00023 l1_ratio 0.75 Penality l1 Train Score 0.8731292517006802 Test Score 0.8533333333333334\n",
      "Alpha 0.00023 l1_ratio 0.75 Penality l2 Train Score 0.9059183673469388 Test Score 0.8665079365079366\n",
      "Alpha 0.00023 l1_ratio 0.85 Penality l1 Train Score 0.871156462585034 Test Score 0.8492063492063492\n",
      "Alpha 0.00023 l1_ratio 0.85 Penality l2 Train Score 0.9070068027210885 Test Score 0.8673015873015874\n",
      "Alpha 0.00023 l1_ratio 0.95 Penality l1 Train Score 0.8695918367346939 Test Score 0.849047619047619\n",
      "Alpha 0.00023 l1_ratio 0.95 Penality l2 Train Score 0.9082312925170068 Test Score 0.8695238095238095\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'alpha':[0.00005,0.00008,0.0001,0.00012,0.00018,0.00023],\n",
    "                    'l1_ratio':[0,0.03,0.05,0.08,0.1,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95],\n",
    "                    'penality':['l1','l2']}):\n",
    "    model = SGDClassifier(penalty=i['penality'],alpha=i['alpha'],l1_ratio=i['l1_ratio'])\n",
    "    model.fit(final_counts_train,X_train.Score)\n",
    "    train_score = model.score(final_counts_train,X_train.Score)\n",
    "    test_score = model.score(X_test,X_test_cv.Score)\n",
    "    print('Alpha',i['alpha'],'l1_ratio',i['l1_ratio'],'Penality',i['penality'],\n",
    "          'Train Score',train_score,'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Random search i didnt got some results wit high l1 ratio and l2 peanality so i dicided to try some low l1 ratios wit same learning rate range and l1 penality. i sisnt get this case in random search. so did some initial investigation above and got some good scores without varince problem also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'sgdclassifier__penalty':['l1','l2'],\n",
    "'sgdclassifier__alpha':[0.00003,0.00005,0.00007,0.00008,0.0001,\n",
    "                           0.00012,0.00018,0.00023],\n",
    "'sgdclassifier__l1_ratio':[0,0.03,0.05,0.08,0.1,0.15,0.25,0.35,0.45,\n",
    "                           0.55,0.65,0.75,0.85,0.95]\n",
    "                    }\n",
    "model_grid_tfidf = GridSearchCV(make_pipeline(TfidfVectorizer(ngram_range=(1,2)),\n",
    "                                            SGDClassifier(n_jobs=-1)),\n",
    "                param_grid=param_grid,cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_grid_tfidf.fit(train_df.final_text,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_tfidf.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['sgdclassifier__alpha'])\n",
    "    dict_score.append(i[0]['sgdclassifier__l1_ratio'])\n",
    "    dict_score.append(i[0]['sgdclassifier__penalty'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_tfidf.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['alpha','l1_ratio','penality','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>penality</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.15</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.929282</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.976729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.929178</td>\n",
       "      <td>0.010054</td>\n",
       "      <td>0.976633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.03</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.929125</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.976605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.05</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.929073</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.976753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.25</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.928968</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>0.976537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.10</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.928968</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.976478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.08</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.928916</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.976547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.45</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.928759</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.976561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.55</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.928654</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.976760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.85</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.928444</td>\n",
       "      <td>0.007099</td>\n",
       "      <td>0.977262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha  l1_ratio penality  Test_score  Test_std  Train_score\n",
       "10  0.00003      0.15       l1    0.929282  0.008460     0.976729\n",
       "0   0.00003      0.00       l1    0.929178  0.010054     0.976633\n",
       "2   0.00003      0.03       l1    0.929125  0.010393     0.976605\n",
       "4   0.00003      0.05       l1    0.929073  0.008819     0.976753\n",
       "12  0.00003      0.25       l1    0.928968  0.008937     0.976537\n",
       "8   0.00003      0.10       l1    0.928968  0.007552     0.976478\n",
       "6   0.00003      0.08       l1    0.928916  0.008576     0.976547\n",
       "16  0.00003      0.45       l1    0.928759  0.008902     0.976561\n",
       "18  0.00003      0.55       l1    0.928654  0.008387     0.976760\n",
       "24  0.00003      0.85       l1    0.928444  0.007099     0.977262"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got best scores at alpha = 0.00003, l1_ratio = 0.15, penalty = l1 and mean cv score is 0.929282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty='l1',alpha=0.00003,l1_ratio=0.15\n",
      "Train Score 0.9569047619047619\n",
      "Test Score 0.9355555555555556\n",
      "Test Precision 0.9517659462308908\n",
      "Test Recall 0.9712210866057019\n",
      "Test ConfusionMatrix [[1198  366]\n",
      " [ 214 7222]]\n"
     ]
    }
   ],
   "source": [
    "#test scores\n",
    "#TFIDF with (1,2) gram with cleaned data \n",
    "#tfidf vec \n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_counts_train = tf_idf_vect.fit_transform(\n",
    "        train_df['final_text'].values)\n",
    "#test\n",
    "X_test = tf_idf_vect.transform(test_df['final_text'].values)\n",
    "\n",
    "model = SGDClassifier(penalty='l1',alpha=0.00003,l1_ratio=0.15)\n",
    "model.fit(final_counts_train,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(final_counts_train)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print(\"penalty='l1',alpha=0.00003,l1_ratio=0.15\")\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "list_of_sent=[]\n",
    "for sent in final_review.final_text.values:\n",
    "    list_of_sent.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec model with 50 dim vector\n",
    "w2v_model_50=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=8)\n",
    "#word2vec model with 100 dim vector\n",
    "w2v_model_100=gensim.models.Word2Vec(list_of_sent,min_count=5,size=100, workers=8)\n",
    "#word2vec model with 300 dim vector\n",
    "w2v_model_300=gensim.models.Word2Vec(list_of_sent,min_count=5,size=300, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to disk\n",
    "pickle.dump(w2v_model_50,open('w2v_model_svm_50.p','wb'))\n",
    "pickle.dump(w2v_model_100,open('w2v_model_svm_100.p','wb'))\n",
    "pickle.dump(w2v_model_300,open('w2v_model_svm_300.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading from disk\n",
    "w2v_model_100 = pickle.load(open('w2v_model_svm_100.p','rb'))\n",
    "w2v_model_50 = pickle.load(open('w2v_model_svm_50.p','rb'))\n",
    "w2v_model_300 = pickle.load(open('w2v_model_svm_300.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the avg-w2v for each sentence/review is stored in this list\n",
    "def avg_w2v(list_of_sent,model,d):\n",
    "    '''\n",
    "    Returns average of word vectors for \n",
    "    each sentance with dimension of model given\n",
    "    '''\n",
    "    sent_vectors = []\n",
    "    for sent in list_of_sent: # for each review/sentence\n",
    "        doc = [word for word in sent if word in model.wv.vocab]\n",
    "        if doc:\n",
    "            sent_vec = np.mean(model.wv[doc],axis=0)\n",
    "        else:\n",
    "            sent_vec = np.zeros(d)\n",
    "        sent_vectors.append(sent_vec)\n",
    "    return sent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sent_train=[]\n",
    "for sent in train_df.final_text.values:\n",
    "    list_of_sent_train.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg word2vec for \n",
    "sent_vector_avgw2v_300 = avg_w2v(list_of_sent_train,w2v_model_300,300)\n",
    "#stacking columns\n",
    "train_avgw2v_300 = np.hstack((sent_vector_avgw2v_300,\n",
    "            train_df[['HelpfulnessNumerator','HelpfulnessDenominator','Score']]))\n",
    "column = list(range(0,300))\n",
    "column.extend(['HelpfulnessNumerator','HelpfulnessDenominator','Score'])\n",
    "train_df_avgw2v_300 = pd.DataFrame(train_avgw2v_300,columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer for BoW\n",
    "X_train = train_df_avgw2v_300.iloc[:round(train_df.shape[0]*0.70),:]\n",
    "X_test_cv = train_df_avgw2v_300.iloc[round(train_df.shape[0]*0.70):,:]\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(X_train.drop('Score',axis=1))\n",
    "X_test_cv_sc = scale.transform(X_test_cv.drop('Score',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.001 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.001 Train Score 0.9078231292517007 Test Score 0.8917460317460317\n",
      "C 0.1 Gamma 0.008 Train Score 0.8776190476190476 Test Score 0.8468253968253968\n",
      "C 0.1 Gamma 0.01 Train Score 0.8648299319727891 Test Score 0.8352380952380952\n",
      "C 0.1 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.001 Train Score 0.9448299319727891 Test Score 0.9274603174603174\n",
      "C 1 Gamma 0.008 Train Score 0.98578231292517 Test Score 0.9068253968253969\n",
      "C 1 Gamma 0.01 Train Score 0.9902721088435374 Test Score 0.8960317460317461\n",
      "C 1 Gamma 0.1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 1 Gamma 0.5 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 1 Gamma 1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 1 Gamma 10 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 5 Gamma 0.001 Train Score 0.9637414965986395 Test Score 0.936031746031746\n",
      "C 5 Gamma 0.008 Train Score 1.0 Test Score 0.9119047619047619\n",
      "C 5 Gamma 0.01 Train Score 1.0 Test Score 0.9014285714285715\n",
      "C 5 Gamma 0.1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 5 Gamma 0.5 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 5 Gamma 1 Train Score 1.0 Test Score 0.8253968253968254\n",
      "C 5 Gamma 10 Train Score 1.0 Test Score 0.8253968253968254\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'C':[0.001,0.01,0.1,1,5],\n",
    "                    'gamma':[0.001,0.008,0.01,0.1,0.5,1,10]}):\n",
    "    model = SVC(C=i['C'],kernel='rbf',gamma=i['gamma'])\n",
    "    model.fit(X_train_sc,X_train.Score)\n",
    "    train_score = model.score(X_train_sc,X_train.Score)\n",
    "    test_score = model.score(X_test_cv_sc,X_test_cv.Score)\n",
    "    print('C',i['C'],'Gamma',i['gamma'],'Train Score',train_score,\n",
    "                     'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that for low values of c we ave ig bias in model and for high values of c we are overfitting to the train data. and for some values of gamma(0.001) and C(1-10) the cv score are better than the others. we do have some generalization error if we are regularizing max also so my be with moderate High C wit low gamma be better for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_avgw2v_300.to_csv('train_df_avgw2v_300_svm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0.8,0.9,1,1.5,3,5,7,10]\n",
    "gamma = [0.0005,0.0008,0.00095,0.001,0.003,0.005,0.008]\n",
    "model_grid_avgw2v = GridSearchCV(make_pipeline(StandardScaler(),\n",
    "                                            SVC()),\n",
    "                            param_grid={'svc__C': c,'svc__gamma':gamma},\n",
    "                        cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_grid_avgw2v.fit(train_df_avgw2v_300.drop('Score',axis=1),train_df_avgw2v_300.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_avgw2v.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_avgw2v.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.933630</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.978743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.933578</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.977413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.00080</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.932897</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.973149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.932216</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>0.973193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.00080</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.932006</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.968160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.931797</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.971904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.931797</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.968227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.931744</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.967187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.931640</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.962913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.00300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.931535</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.993881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gamma     C  Test_score  Test_std  Train_score\n",
       "52  0.00100  10.0    0.933630  0.006818     0.978743\n",
       "51  0.00095  10.0    0.933578  0.006756     0.977413\n",
       "50  0.00080  10.0    0.932897  0.006800     0.973149\n",
       "45  0.00100   7.0    0.932216  0.006664     0.973193\n",
       "43  0.00080   7.0    0.932006  0.007466     0.968160\n",
       "44  0.00095   7.0    0.931797  0.007015     0.971904\n",
       "38  0.00100   5.0    0.931797  0.007716     0.968227\n",
       "37  0.00095   5.0    0.931744  0.007464     0.967187\n",
       "49  0.00050  10.0    0.931640  0.006226     0.962913\n",
       "39  0.00300   5.0    0.931535  0.004997     0.993881"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [10,20,30,40,50,60,70,80,90,100]\n",
    "gamma = [0.00095,0.001]\n",
    "model_grid_avgw2v2 = GridSearchCV(make_pipeline(StandardScaler(),\n",
    "                                            SVC()),\n",
    "                             param_grid={'svc__C': c,'svc__gamma':gamma},\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_grid_avgw2v2.fit(train_df_avgw2v_300.drop('Score',axis=1),train_df_avgw2v_300.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_avgw2v2.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_avgw2v2.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df2 = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.933630</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.978743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>10</td>\n",
       "      <td>0.933578</td>\n",
       "      <td>0.006756</td>\n",
       "      <td>0.977413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.932111</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.987762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>20</td>\n",
       "      <td>0.931640</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.986663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.931221</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.992037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>30</td>\n",
       "      <td>0.931116</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>0.991255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>40</td>\n",
       "      <td>0.930906</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.993642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.930592</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.994460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>50</td>\n",
       "      <td>0.930016</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.995593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>0.996349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gamma   C  Test_score  Test_std  Train_score\n",
       "1  0.00100  10    0.933630  0.006818     0.978743\n",
       "0  0.00095  10    0.933578  0.006756     0.977413\n",
       "3  0.00100  20    0.932111  0.006485     0.987762\n",
       "2  0.00095  20    0.931640  0.007013     0.986663\n",
       "5  0.00100  30    0.931221  0.006858     0.992037\n",
       "4  0.00095  30    0.931116  0.006455     0.991255\n",
       "6  0.00095  40    0.930906  0.006735     0.993642\n",
       "7  0.00100  40    0.930592  0.007110     0.994460\n",
       "8  0.00095  50    0.930016  0.007068     0.995593\n",
       "9  0.00100  50    0.929387  0.006629     0.996349"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df2.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "model_random_avgw2v = RandomizedSearchCV(make_pipeline(StandardScaler(),SVC()),\n",
    "                     param_distributions={'svc__C': uniform(loc=0,scale=13),\n",
    "                     'svc__gamma':uniform(loc=0.0008,scale=0.004)},n_iter=25,\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1)\n",
    "model_random_avgw2v.fit(train_df_avgw2v_300.drop('Score',axis=1),train_df_avgw2v_300.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_avgw2v.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_avgw2v.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df1 = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001337</td>\n",
       "      <td>7.135116</td>\n",
       "      <td>0.932792</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.980713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001729</td>\n",
       "      <td>6.847431</td>\n",
       "      <td>0.932740</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.986392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001961</td>\n",
       "      <td>4.655458</td>\n",
       "      <td>0.932635</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.983589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001799</td>\n",
       "      <td>6.445765</td>\n",
       "      <td>0.932583</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.986443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001156</td>\n",
       "      <td>12.931930</td>\n",
       "      <td>0.932478</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.985614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001583</td>\n",
       "      <td>10.511907</td>\n",
       "      <td>0.932373</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.990104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002504</td>\n",
       "      <td>3.154084</td>\n",
       "      <td>0.932216</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.983583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002473</td>\n",
       "      <td>5.143757</td>\n",
       "      <td>0.932163</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.990524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001417</td>\n",
       "      <td>12.460012</td>\n",
       "      <td>0.932111</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.989660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002093</td>\n",
       "      <td>2.559956</td>\n",
       "      <td>0.931954</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.975369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma          C  Test_score  Test_std  Train_score\n",
       "0   0.001337   7.135116    0.932792  0.006643     0.980713\n",
       "21  0.001729   6.847431    0.932740  0.006190     0.986392\n",
       "5   0.001961   4.655458    0.932635  0.006548     0.983589\n",
       "19  0.001799   6.445765    0.932583  0.006304     0.986443\n",
       "22  0.001156  12.931930    0.932478  0.006379     0.985614\n",
       "13  0.001583  10.511907    0.932373  0.006640     0.990104\n",
       "1   0.002504   3.154084    0.932216  0.006163     0.983583\n",
       "12  0.002473   5.143757    0.932163  0.006208     0.990524\n",
       "18  0.001417  12.460012    0.932111  0.006425     0.989660\n",
       "16  0.002093   2.559956    0.931954  0.006908     0.975369"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df1.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best cv score for 10 fold cv got at `gamma = 0.00100, C = 10` and mean cv score is `0.933630`\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 10 gamma 0.001\n",
      "Train Score 0.9725714285714285\n",
      "Test Score 0.9332222222222222\n",
      "Test Precision 0.9459741615555266\n",
      "Test Recall 0.9748520710059172\n",
      "Test ConfusionMatrix [[1150  414]\n",
      " [ 187 7249]]\n",
      "No of support vectors for each class [1693 2078]\n"
     ]
    }
   ],
   "source": [
    "#testscore\n",
    "list_of_sent_train=[]\n",
    "for sent in train_df.final_text.values:\n",
    "    list_of_sent_train.append(sent.split())\n",
    "#avg word2vec for \n",
    "sent_vector_avgw2v_300 = avg_w2v(list_of_sent_train,w2v_model_300,300)\n",
    "#stacking columns\n",
    "train_avgw2v_300 = np.hstack((sent_vector_avgw2v_300,\n",
    "            train_df[['HelpfulnessNumerator','HelpfulnessDenominator','Score']]))\n",
    "column = list(range(0,300))\n",
    "column.extend(['HelpfulnessNumerator','HelpfulnessDenominator','Score'])\n",
    "train_df_avgw2v_300 = pd.DataFrame(train_avgw2v_300,columns=column)\n",
    "\n",
    "\n",
    "list_of_sent_test=[]\n",
    "for sent in test_df.final_text.values:\n",
    "    list_of_sent_test.append(sent.split())\n",
    "#avg word2vec for \n",
    "sent_vector_avgw2v_300_test = avg_w2v(list_of_sent_test,w2v_model_300,300)\n",
    "#stacking columns\n",
    "test_avgw2v_300 = np.hstack((sent_vector_avgw2v_300_test,\n",
    "            test_df[['HelpfulnessNumerator','HelpfulnessDenominator','Score']]))\n",
    "column = list(range(0,300))\n",
    "column.extend(['HelpfulnessNumerator','HelpfulnessDenominator','Score'])\n",
    "test_df_avgw2v_300 = pd.DataFrame(test_avgw2v_300,columns=column)\n",
    "\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(train_df_avgw2v_300.drop('Score',axis=1))\n",
    "X_test_cv_sc = scale.transform(test_df_avgw2v_300.drop('Score',axis=1))\n",
    "\n",
    "\n",
    "model = SVC(C=10,kernel='rbf',gamma=0.00100)\n",
    "model.fit(X_train_sc,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(X_train_sc)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test_cv_sc)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print('C' ,10,'gamma',0.00100)\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)\n",
    "print('No of support vectors for each class',model.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 5e-05 l1_ratio 0 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0 Penality elasticnet Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality elasticnet Train Score 0.9377551020408164 Test Score 0.9250793650793651\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality elasticnet Train Score 0.9386394557823129 Test Score 0.9258730158730158\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality elasticnet Train Score 0.9385034013605442 Test Score 0.9255555555555556\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality elasticnet Train Score 0.9387074829931973 Test Score 0.9277777777777778\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality elasticnet Train Score 0.9374829931972789 Test Score 0.9230158730158731\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality elasticnet Train Score 0.939047619047619 Test Score 0.9261904761904762\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality elasticnet Train Score 0.9387074829931973 Test Score 0.9265079365079365\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality elasticnet Train Score 0.9392517006802721 Test Score 0.9273015873015873\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality elasticnet Train Score 0.941156462585034 Test Score 0.9298412698412698\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality elasticnet Train Score 0.9406802721088435 Test Score 0.9263492063492064\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality elasticnet Train Score 0.9422448979591836 Test Score 0.9292063492063493\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality elasticnet Train Score 0.9417006802721088 Test Score 0.929047619047619\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality l1 Train Score 0.9415646258503402 Test Score 0.9293650793650794\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality l2 Train Score 0.9393197278911565 Test Score 0.927936507936508\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality elasticnet Train Score 0.943469387755102 Test Score 0.9274603174603174\n",
      "Alpha 8e-05 l1_ratio 0 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0 Penality elasticnet Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality elasticnet Train Score 0.937687074829932 Test Score 0.9236507936507936\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality elasticnet Train Score 0.9385034013605442 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality elasticnet Train Score 0.9373469387755102 Test Score 0.9233333333333333\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality elasticnet Train Score 0.9389115646258503 Test Score 0.923968253968254\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality elasticnet Train Score 0.9386394557823129 Test Score 0.923968253968254\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality elasticnet Train Score 0.939047619047619 Test Score 0.9257142857142857\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality elasticnet Train Score 0.9385714285714286 Test Score 0.9255555555555556\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality elasticnet Train Score 0.9403401360544218 Test Score 0.9265079365079365\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality elasticnet Train Score 0.9396598639455782 Test Score 0.926984126984127\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality elasticnet Train Score 0.9417006802721088 Test Score 0.9280952380952381\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality elasticnet Train Score 0.9415646258503402 Test Score 0.929047619047619\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality elasticnet Train Score 0.9398639455782313 Test Score 0.9280952380952381\n",
      "Alpha 8e-05 l1_ratio 0.95 Penality l1 Train Score 0.9438095238095238 Test Score 0.9285714285714286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 8e-05 l1_ratio 0.95 Penality l2 Train Score 0.9384353741496598 Test Score 0.9246031746031746\n",
      "Alpha 8e-05 l1_ratio 0.95 Penality elasticnet Train Score 0.9425850340136055 Test Score 0.9273015873015873\n",
      "Alpha 0.0001 l1_ratio 0 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0 Penality elasticnet Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality elasticnet Train Score 0.9374829931972789 Test Score 0.9223809523809524\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality elasticnet Train Score 0.9378231292517006 Test Score 0.9241269841269841\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality elasticnet Train Score 0.9373469387755102 Test Score 0.9233333333333333\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality elasticnet Train Score 0.9380272108843537 Test Score 0.9236507936507936\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality elasticnet Train Score 0.9380272108843537 Test Score 0.9238095238095239\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality elasticnet Train Score 0.9382993197278912 Test Score 0.9242857142857143\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality elasticnet Train Score 0.9391836734693878 Test Score 0.9238095238095239\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality elasticnet Train Score 0.940204081632653 Test Score 0.9255555555555556\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality elasticnet Train Score 0.9401360544217687 Test Score 0.9274603174603174\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality elasticnet Train Score 0.9406802721088435 Test Score 0.926984126984127\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality elasticnet Train Score 0.9400680272108843 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality elasticnet Train Score 0.9415646258503402 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality l1 Train Score 0.9437414965986395 Test Score 0.927936507936508\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality l2 Train Score 0.9366666666666666 Test Score 0.9228571428571428\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality elasticnet Train Score 0.9410884353741497 Test Score 0.9266666666666666\n",
      "Alpha 0.00012 l1_ratio 0 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0 Penality elasticnet Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality elasticnet Train Score 0.9372789115646258 Test Score 0.9225396825396825\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality elasticnet Train Score 0.9374149659863945 Test Score 0.9222222222222223\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality elasticnet Train Score 0.9379591836734694 Test Score 0.9234920634920635\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality elasticnet Train Score 0.9379591836734694 Test Score 0.9231746031746032\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality elasticnet Train Score 0.9386394557823129 Test Score 0.9231746031746032\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality elasticnet Train Score 0.9379591836734694 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality elasticnet Train Score 0.9382993197278912 Test Score 0.9242857142857143\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality elasticnet Train Score 0.9382993197278912 Test Score 0.9253968253968254\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality elasticnet Train Score 0.9393197278911565 Test Score 0.9263492063492064\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality elasticnet Train Score 0.9402721088435374 Test Score 0.9276190476190476\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality elasticnet Train Score 0.9406122448979591 Test Score 0.9280952380952381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.00012 l1_ratio 0.85 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.85 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.85 Penality elasticnet Train Score 0.9415646258503402 Test Score 0.9261904761904762\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality l1 Train Score 0.9426530612244898 Test Score 0.9273015873015873\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality l2 Train Score 0.9385714285714286 Test Score 0.923968253968254\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality elasticnet Train Score 0.9427210884353742 Test Score 0.9282539682539682\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'alpha':[0.00005,0.00008,0.0001,0.00012],\n",
    "                    'l1_ratio':[0,0.03,0.05,0.08,0.1,0.15,0.25,0.35,\n",
    "                                   0.45,0.55,0.65,0.75,0.85,0.95],\n",
    "                    'penality':['l1','l2','elasticnet']}):\n",
    "    model = SGDClassifier(penalty=i['penality'],alpha=i['alpha'],l1_ratio=i['l1_ratio'],random_state=25)\n",
    "    model.fit(X_train_sc,X_train.Score)\n",
    "    train_score = model.score(X_train_sc,X_train.Score)\n",
    "    test_score = model.score(X_test_cv_sc,X_test_cv.Score)\n",
    "    print('Alpha',i['alpha'],'l1_ratio',i['l1_ratio'],'Penality',i['penality'],\n",
    "          'Train Score',train_score,'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'sgdclassifier__penalty':['l1','l2','elasticnet'],\n",
    "'sgdclassifier__alpha':[0.00003,0.00005,0.00007,0.00008,0.0001,\n",
    "                                    0.00012,0.00018,0.00023],\n",
    "'sgdclassifier__l1_ratio':[0,0.03,0.05,0.08,0.1,0.15,0.25,0.35,\n",
    "                               0.45,0.55,0.65,0.75,0.85,0.95]}\n",
    "model_grid_avgw2v = GridSearchCV(make_pipeline(StandardScaler(),\n",
    "                                        SGDClassifier(n_jobs=-1)),\n",
    "                                           param_grid=param_grid,\n",
    "                                 cv=TimeSeriesSplit(n_splits=10),\n",
    "                                                      n_jobs=-1)\n",
    "model_grid_avgw2v.fit(train_df_avgw2v_300.drop('Score',axis=1),train_df_avgw2v_300.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_avgw2v.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['sgdclassifier__alpha'])\n",
    "    dict_score.append(i[0]['sgdclassifier__l1_ratio'])\n",
    "    dict_score.append(i[0]['sgdclassifier__penalty'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_avgw2v.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['alpha','l1_ratio','penalty','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>penalty</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.25</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.925406</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.949701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.35</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.925354</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.949089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.95</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.925039</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.948532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.03</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.924987</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.948186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.45</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.924935</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.949894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.45</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.924830</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.948310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.25</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.924725</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.948830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.10</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.924673</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.950189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.08</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.924515</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.948358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.85</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.924463</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.943389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha  l1_ratio     penalty  Test_score  Test_std  Train_score\n",
       "228  0.00012      0.25          l1    0.925406  0.005465     0.949701\n",
       "231  0.00012      0.35          l1    0.925354  0.008048     0.949089\n",
       "251  0.00012      0.95  elasticnet    0.925039  0.007527     0.948532\n",
       "213  0.00012      0.03          l1    0.924987  0.006550     0.948186\n",
       "66   0.00005      0.45          l1    0.924935  0.005871     0.949894\n",
       "234  0.00012      0.45          l1    0.924830  0.006851     0.948310\n",
       "186  0.00010      0.25          l1    0.924725  0.006626     0.948830\n",
       "138  0.00008      0.10          l1    0.924673  0.004765     0.950189\n",
       "177  0.00010      0.08          l1    0.924515  0.005506     0.948358\n",
       "79   0.00005      0.85          l2    0.924463  0.005463     0.943389"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got best cv mean score at alpha = 0.00012,l1_ratio= 0.25 penlty = l1 and mean cv score is 0.925406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With SGD\n",
      "penalty='l1',alpha=0.00012,l1_ratio=0.25\n",
      "Train Score 0.9392380952380952\n",
      "Test Score 0.9287777777777778\n",
      "Test Precision 0.9474516001580403\n",
      "Test Recall 0.9674556213017751\n",
      "Test ConfusionMatrix [[1165  399]\n",
      " [ 242 7194]]\n"
     ]
    }
   ],
   "source": [
    "print('With SGD')\n",
    "#testscore\n",
    "list_of_sent_train=[]\n",
    "for sent in train_df.final_text.values:\n",
    "    list_of_sent_train.append(sent.split())\n",
    "#avg word2vec for \n",
    "sent_vector_avgw2v_300 = avg_w2v(list_of_sent_train,w2v_model_300,300)\n",
    "#stacking columns\n",
    "train_avgw2v_300 = np.hstack((sent_vector_avgw2v_300,\n",
    "            train_df[['HelpfulnessNumerator','HelpfulnessDenominator','Score']]))\n",
    "column = list(range(0,300))\n",
    "column.extend(['HelpfulnessNumerator','HelpfulnessDenominator','Score'])\n",
    "train_df_avgw2v_300 = pd.DataFrame(train_avgw2v_300,columns=column)\n",
    "\n",
    "\n",
    "list_of_sent_test=[]\n",
    "for sent in test_df.final_text.values:\n",
    "    list_of_sent_test.append(sent.split())\n",
    "#avg word2vec for \n",
    "sent_vector_avgw2v_300_test = avg_w2v(list_of_sent_test,w2v_model_300,300)\n",
    "#stacking columns\n",
    "test_avgw2v_300 = np.hstack((sent_vector_avgw2v_300_test,\n",
    "            test_df[['HelpfulnessNumerator','HelpfulnessDenominator','Score']]))\n",
    "column = list(range(0,300))\n",
    "column.extend(['HelpfulnessNumerator','HelpfulnessDenominator','Score'])\n",
    "test_df_avgw2v_300 = pd.DataFrame(test_avgw2v_300,columns=column)\n",
    "\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(train_df_avgw2v_300.drop('Score',axis=1))\n",
    "X_test_cv_sc = scale.transform(test_df_avgw2v_300.drop('Score',axis=1))\n",
    "\n",
    "\n",
    "model =  SGDClassifier(penalty='l1',alpha=0.00012,l1_ratio=0.25,random_state=25)\n",
    "model.fit(X_train_sc,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(X_train_sc)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test_cv_sc)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print(\"penalty='l1',alpha=0.00012,l1_ratio=0.25\")\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TfidfWeightedWord2Vec(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Class for Tfidf Weighted Word2Vec Calculations\n",
    "    '''\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = word2vec.vector_size\n",
    "        self.tfidf = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        tfidf = TfidfVectorizer()\n",
    "        tfidf.fit(X[:,0])\n",
    "        self.tfidf = tfidf\n",
    "        #print(self.word2vec.wv.vocab.keys())\n",
    "        return self\n",
    "    \n",
    "    def tf_idf_W2V(self,feature_names,tf_idf_trans_arr,list_of_sent):\n",
    "        '''\n",
    "        tfidf weighted word2vec calculation\n",
    "        '''\n",
    "        import operator\n",
    "        dict_tfidf = {k: v for v, k in enumerate(feature_names)}\n",
    "        sent_vectors = []\n",
    "        i = 0\n",
    "        for sent in list_of_sent: # for each review/sentence\n",
    "            doc = [word for word in sent if word in self.word2vec.wv.vocab.keys()]\n",
    "            if doc:\n",
    "                #itemgetter\n",
    "                f = operator.itemgetter(*doc)\n",
    "                try:\n",
    "                    #itemgetter from dict\n",
    "                    final = f(dict_tfidf)\n",
    "                    final = tf_idf_trans_arr[i,final]\n",
    "                    #converting to dense\n",
    "                    final = final.toarray()\n",
    "                    #converting to diagnol matrix for multiplication\n",
    "                    final= np.diag(final[0])\n",
    "                    sent_vec = np.dot(final,np.array(self.word2vec.wv[doc]))\n",
    "                    #tfidf weighted word to vec\n",
    "                    sent_vec = np.sum(sent_vec,axis=0) / np.sum(final)\n",
    "                except:\n",
    "                    sent_vec = np.zeros(self.dim)             \n",
    "            else:\n",
    "                sent_vec = np.zeros(self.dim)\n",
    "            sent_vectors.append(sent_vec)\n",
    "            i = i+1\n",
    "        return sent_vectors\n",
    "\n",
    "    def transform(self, X):\n",
    "        #transform data\n",
    "        tf_idf_trans_arr = self.tfidf.transform(X[:,0])\n",
    "        feature_names = self.tfidf.get_feature_names()\n",
    "        list_of_sent = []\n",
    "        for sent in X[:,0]:\n",
    "            list_of_sent.append(sent.split())\n",
    "        temp_vec = self.tf_idf_W2V(feature_names,tf_idf_trans_arr,list_of_sent)\n",
    "        temp_vec= np.hstack((temp_vec,X[:,[1,2]]))\n",
    "        return temp_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simple cv\n",
    "#Train data\n",
    "X_train = train_df.iloc[:round(train_df.shape[0]*0.70),:]\n",
    "X_test_cv = train_df.iloc[round(train_df.shape[0]*0.70):,:]\n",
    "#transforming to tfidf weighted word2vec\n",
    "tfidfvect_w2v = TfidfWeightedWord2Vec(w2v_model_300)\n",
    "tfidfvect_w2v.fit(X_train[['final_text','HelpfulnessNumerator',\n",
    "                           'HelpfulnessDenominator']].values)\n",
    "X_train_tfw2v = tfidfvect_w2v.transform(X_train[['final_text',\n",
    "                'HelpfulnessNumerator','HelpfulnessDenominator']].values)\n",
    "X_cv_tfw2v = tfidfvect_w2v.transform(X_test_cv[['final_text',\n",
    "                 'HelpfulnessNumerator','HelpfulnessDenominator']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(X_train_tfw2v)\n",
    "X_test_cv_sc = scale.transform(X_cv_tfw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 1 Gamma 0.001 Train Score 0.9242857142857143 Test Score 0.8833333333333333\n",
      "C 1 Gamma 0.008 Train Score 0.9641496598639456 Test Score 0.8671428571428571\n",
      "C 1 Gamma 0.01 Train Score 0.9679591836734693 Test Score 0.8611111111111112\n",
      "C 1 Gamma 0.1 Train Score 0.9785714285714285 Test Score 0.8268253968253968\n",
      "C 1 Gamma 0.5 Train Score 0.9789795918367347 Test Score 0.8287301587301588\n",
      "C 1 Gamma 1 Train Score 0.9792517006802721 Test Score 0.829047619047619\n",
      "C 1 Gamma 10 Train Score 0.9814285714285714 Test Score 0.8323809523809523\n",
      "C 5 Gamma 0.001 Train Score 0.9479591836734694 Test Score 0.8898412698412699\n",
      "C 5 Gamma 0.008 Train Score 0.9782993197278912 Test Score 0.87\n",
      "C 5 Gamma 0.01 Train Score 0.9786394557823129 Test Score 0.8653968253968254\n",
      "C 5 Gamma 0.1 Train Score 0.978843537414966 Test Score 0.8274603174603175\n",
      "C 5 Gamma 0.5 Train Score 0.9793877551020408 Test Score 0.8282539682539682\n",
      "C 5 Gamma 1 Train Score 0.9798639455782313 Test Score 0.8304761904761905\n",
      "C 5 Gamma 10 Train Score 0.9821768707482993 Test Score 0.8320634920634921\n",
      "C 7 Gamma 0.001 Train Score 0.9527210884353742 Test Score 0.8895238095238095\n",
      "C 7 Gamma 0.008 Train Score 0.9785714285714285 Test Score 0.8701587301587301\n",
      "C 7 Gamma 0.01 Train Score 0.9785034013605443 Test Score 0.8653968253968254\n",
      "C 7 Gamma 0.1 Train Score 0.9787755102040816 Test Score 0.8274603174603175\n",
      "C 7 Gamma 0.5 Train Score 0.9795238095238096 Test Score 0.8284126984126984\n",
      "C 7 Gamma 1 Train Score 0.980204081632653 Test Score 0.8314285714285714\n",
      "C 7 Gamma 10 Train Score 0.9823129251700681 Test Score 0.8319047619047619\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'C':[1,5,7],\n",
    "                    'gamma':[0.001,0.008,0.01,0.1,0.5,1,10]}):\n",
    "    model = SVC(C=i['C'],kernel='rbf',gamma=i['gamma'])\n",
    "    model.fit(X_train_sc,X_train.Score)\n",
    "    train_score = model.score(X_train_sc,X_train.Score)\n",
    "    test_score = model.score(X_test_cv_sc,X_test_cv.Score)\n",
    "    print('C',i['C'],'Gamma',i['gamma'],'Train Score',train_score,\n",
    "                     'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 0.001 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.001 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.001 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.008 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.01 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 0.5 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.01 Gamma 10 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.001 Train Score 0.8851020408163265 Test Score 0.8536507936507937\n",
      "C 0.1 Gamma 0.008 Train Score 0.8639455782312925 Test Score 0.8319047619047619\n",
      "C 0.1 Gamma 0.01 Train Score 0.8584353741496599 Test Score 0.8273015873015873\n",
      "C 0.1 Gamma 0.1 Train Score 0.8563945578231292 Test Score 0.8253968253968254\n",
      "C 0.1 Gamma 0.5 Train Score 0.8571428571428571 Test Score 0.8258730158730159\n",
      "C 0.1 Gamma 1 Train Score 0.8572789115646259 Test Score 0.8257142857142857\n",
      "C 0.1 Gamma 10 Train Score 0.8565986394557823 Test Score 0.8257142857142857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'C':[0.001,0.01,0.1],\n",
    "                    'gamma':[0.001,0.008,0.01,0.1,0.5,1,10]}):\n",
    "    model = SVC(C=i['C'],kernel='rbf',gamma=i['gamma'])\n",
    "    model.fit(X_train_sc,X_train.Score)\n",
    "    train_score = model.score(X_train_sc,X_train.Score)\n",
    "    test_score = model.score(X_test_cv_sc,X_test_cv.Score)\n",
    "    print('C',i['C'],'Gamma',i['gamma'],'Train Score',train_score,\n",
    "                     'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [10.5,0.85,1,2.5,5,10,12,20]\n",
    "gamma = [0.00095,0.001,0.0013,0.0015,0.0024,0.007,0.01,1,10]\n",
    "model_grid_tfidfw2v = GridSearchCV(\n",
    "                            make_pipeline(TfidfWeightedWord2Vec(w2v_model_300),\n",
    "                            StandardScaler(),SVC()),\n",
    "                             param_grid={'svc__C': c,'svc__gamma':gamma},\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1) \n",
    "model_grid_tfidfw2v.fit(train_df[['final_text','HelpfulnessNumerator',\n",
    "                            'HelpfulnessDenominator']].values,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_grid_tfidfw2v.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_grid_tfidfw2v.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.892457</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.972534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.892404</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.971365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.892142</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.964579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00130</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.969587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.965825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00130</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.892038</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.970219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.00130</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.892038</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.971907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.891933</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.963971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.891776</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.962865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.00095</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.891776</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.961995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gamma     C  Test_score  Test_std  Train_score\n",
       "64  0.00100  20.0    0.892457  0.004307     0.972534\n",
       "63  0.00095  20.0    0.892404  0.004359     0.971365\n",
       "54  0.00095  12.0    0.892142  0.005162     0.964579\n",
       "47  0.00130  10.0    0.892090  0.005534     0.969587\n",
       "55  0.00100  12.0    0.892090  0.005008     0.965825\n",
       "2   0.00130  10.5    0.892038  0.005365     0.970219\n",
       "56  0.00130  12.0    0.892038  0.005081     0.971907\n",
       "1   0.00100  10.5    0.891933  0.006247     0.963971\n",
       "0   0.00095  10.5    0.891776  0.005768     0.962865\n",
       "45  0.00095  10.0    0.891776  0.006028     0.961995"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random_tfidfw2v = RandomizedSearchCV(\n",
    "                        make_pipeline(TfidfWeightedWord2Vec(w2v_model_300),\n",
    "                            StandardScaler(),SVC()),\n",
    "                        param_distributions={'svc__C': uniform(loc=0,scale=3.5),\n",
    "                        'svc__gamma':uniform(loc=0.0008,scale=0.004)},n_iter=15,\n",
    "                            cv=TimeSeriesSplit(n_splits=10),n_jobs=-1) \n",
    "model_random_tfidfw2v.fit(train_df[['final_text','HelpfulnessNumerator',\n",
    "                                'HelpfulnessDenominator']].values,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_tfidfw2v.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['svc__gamma'])\n",
    "    dict_score.append(i[0]['svc__C'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_tfidfw2v.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['gamma','C','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>C</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002625</td>\n",
       "      <td>2.978150</td>\n",
       "      <td>0.889314</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.968132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002274</td>\n",
       "      <td>2.929955</td>\n",
       "      <td>0.889104</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.964255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003434</td>\n",
       "      <td>3.078954</td>\n",
       "      <td>0.887742</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.974421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003403</td>\n",
       "      <td>2.501247</td>\n",
       "      <td>0.887690</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.971187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003382</td>\n",
       "      <td>3.446907</td>\n",
       "      <td>0.887533</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.975409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002573</td>\n",
       "      <td>1.670520</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.955952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003608</td>\n",
       "      <td>2.015362</td>\n",
       "      <td>0.886695</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.968607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003702</td>\n",
       "      <td>2.062496</td>\n",
       "      <td>0.886433</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.969583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003818</td>\n",
       "      <td>2.920594</td>\n",
       "      <td>0.886276</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.975324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004238</td>\n",
       "      <td>2.525873</td>\n",
       "      <td>0.885961</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.975278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gamma         C  Test_score  Test_std  Train_score\n",
       "5   0.002625  2.978150    0.889314  0.006145     0.968132\n",
       "11  0.002274  2.929955    0.889104  0.005996     0.964255\n",
       "10  0.003434  3.078954    0.887742  0.006286     0.974421\n",
       "4   0.003403  2.501247    0.887690  0.006506     0.971187\n",
       "12  0.003382  3.446907    0.887533  0.006390     0.975409\n",
       "6   0.002573  1.670520    0.887218  0.006713     0.955952\n",
       "9   0.003608  2.015362    0.886695  0.006492     0.968607\n",
       "7   0.003702  2.062496    0.886433  0.006320     0.969583\n",
       "14  0.003818  2.920594    0.886276  0.006151     0.975324\n",
       "0   0.004238  2.525873    0.885961  0.006509     0.975278"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best cv score for tfidf word2vec got at gamma = 0.00100\tC = 20.0 and mean cv score is 0.892457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 20 gamma 0.001\n",
      "Train Score 0.9643809523809523\n",
      "Test Score 0.8904444444444445\n",
      "Test Precision 0.8969719350073855\n",
      "Test Recall 0.9799623453469607\n",
      "Test ConfusionMatrix [[ 727  837]\n",
      " [ 149 7287]]\n",
      "No of support vectors for each class [2031 2750]\n"
     ]
    }
   ],
   "source": [
    "#testscore\n",
    "# For simple cv\n",
    "#transforming to tfidf weighted word2vec\n",
    "tfidfvect_w2v = TfidfWeightedWord2Vec(w2v_model_300)\n",
    "tfidfvect_w2v.fit(train_df[['final_text','HelpfulnessNumerator',\n",
    "                           'HelpfulnessDenominator']].values)\n",
    "X_train_tfw2v = tfidfvect_w2v.transform(train_df[['final_text',\n",
    "                'HelpfulnessNumerator','HelpfulnessDenominator']].values)\n",
    "X_cv_tfw2v = tfidfvect_w2v.transform(test_df[['final_text',\n",
    "                 'HelpfulnessNumerator','HelpfulnessDenominator']].values)\n",
    "\n",
    "#scaling the data\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(X_train_tfw2v)\n",
    "X_test_cv_sc = scale.transform(X_cv_tfw2v)\n",
    "\n",
    "model = SVC(C=20,kernel='rbf',gamma=0.00100)\n",
    "model.fit(X_train_sc,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(X_train_sc)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test_cv_sc)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print('C' ,20,'gamma',0.00100)\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)\n",
    "print('No of support vectors for each class',model.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 5e-05 l1_ratio 0 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0 Penality elasticnet Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.03 Penality elasticnet Train Score 0.9169387755102041 Test Score 0.8917460317460317\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.05 Penality elasticnet Train Score 0.9196598639455782 Test Score 0.8933333333333333\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.08 Penality elasticnet Train Score 0.9186394557823129 Test Score 0.8884126984126984\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.1 Penality elasticnet Train Score 0.9102040816326531 Test Score 0.8865079365079365\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.15 Penality elasticnet Train Score 0.9124489795918367 Test Score 0.8831746031746032\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.25 Penality elasticnet Train Score 0.9208163265306123 Test Score 0.8923809523809524\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.35 Penality elasticnet Train Score 0.9231972789115647 Test Score 0.8953968253968254\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.45 Penality elasticnet Train Score 0.922312925170068 Test Score 0.8933333333333333\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.55 Penality elasticnet Train Score 0.9128571428571428 Test Score 0.883968253968254\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.65 Penality elasticnet Train Score 0.9136734693877551 Test Score 0.8855555555555555\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.75 Penality elasticnet Train Score 0.9219727891156463 Test Score 0.8926984126984127\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.85 Penality elasticnet Train Score 0.9263945578231293 Test Score 0.8974603174603175\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality l1 Train Score 0.9236734693877551 Test Score 0.8922222222222222\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality l2 Train Score 0.9210884353741496 Test Score 0.8890476190476191\n",
      "Alpha 5e-05 l1_ratio 0.95 Penality elasticnet Train Score 0.9259863945578232 Test Score 0.8965079365079365\n",
      "Alpha 8e-05 l1_ratio 0 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0 Penality elasticnet Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.03 Penality elasticnet Train Score 0.9195238095238095 Test Score 0.8931746031746032\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.05 Penality elasticnet Train Score 0.9224489795918367 Test Score 0.8944444444444445\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.08 Penality elasticnet Train Score 0.9149659863945578 Test Score 0.8860317460317461\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.1 Penality elasticnet Train Score 0.9220408163265306 Test Score 0.893015873015873\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.15 Penality elasticnet Train Score 0.9148979591836734 Test Score 0.8853968253968254\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.25 Penality elasticnet Train Score 0.9210884353741496 Test Score 0.8936507936507937\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.35 Penality elasticnet Train Score 0.9227210884353741 Test Score 0.8946031746031746\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.45 Penality elasticnet Train Score 0.9160544217687074 Test Score 0.8896825396825396\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.55 Penality elasticnet Train Score 0.9230612244897959 Test Score 0.8961904761904762\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.65 Penality elasticnet Train Score 0.9244897959183673 Test Score 0.8957142857142857\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.75 Penality elasticnet Train Score 0.925578231292517 Test Score 0.8942857142857142\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.85 Penality elasticnet Train Score 0.923265306122449 Test Score 0.8968253968253969\n",
      "Alpha 8e-05 l1_ratio 0.95 Penality l1 Train Score 0.9240136054421769 Test Score 0.8949206349206349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 8e-05 l1_ratio 0.95 Penality l2 Train Score 0.9206122448979592 Test Score 0.8920634920634921\n",
      "Alpha 8e-05 l1_ratio 0.95 Penality elasticnet Train Score 0.9178231292517007 Test Score 0.8874603174603175\n",
      "Alpha 0.0001 l1_ratio 0 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0 Penality elasticnet Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.03 Penality elasticnet Train Score 0.921156462585034 Test Score 0.8931746031746032\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.05 Penality elasticnet Train Score 0.921156462585034 Test Score 0.8928571428571429\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.08 Penality elasticnet Train Score 0.9155102040816326 Test Score 0.8863492063492063\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.1 Penality elasticnet Train Score 0.9214965986394558 Test Score 0.8934920634920634\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.15 Penality elasticnet Train Score 0.9210884353741496 Test Score 0.8934920634920634\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.25 Penality elasticnet Train Score 0.9206122448979592 Test Score 0.895079365079365\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.35 Penality elasticnet Train Score 0.9197278911564626 Test Score 0.8884126984126984\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.45 Penality elasticnet Train Score 0.9230612244897959 Test Score 0.8938095238095238\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.55 Penality elasticnet Train Score 0.9242857142857143 Test Score 0.8953968253968254\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.65 Penality elasticnet Train Score 0.92421768707483 Test Score 0.8949206349206349\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.75 Penality elasticnet Train Score 0.9238095238095239 Test Score 0.8952380952380953\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.85 Penality elasticnet Train Score 0.9238775510204081 Test Score 0.8952380952380953\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality l1 Train Score 0.9182312925170067 Test Score 0.89\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality l2 Train Score 0.9231292517006803 Test Score 0.893968253968254\n",
      "Alpha 0.0001 l1_ratio 0.95 Penality elasticnet Train Score 0.9229251700680272 Test Score 0.8953968253968254\n",
      "Alpha 0.00012 l1_ratio 0 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0 Penality elasticnet Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.03 Penality elasticnet Train Score 0.9204761904761904 Test Score 0.8949206349206349\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.05 Penality elasticnet Train Score 0.9219727891156463 Test Score 0.8934920634920634\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.08 Penality elasticnet Train Score 0.9227210884353741 Test Score 0.8919047619047619\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.1 Penality elasticnet Train Score 0.9228571428571428 Test Score 0.8941269841269841\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.15 Penality elasticnet Train Score 0.9222448979591836 Test Score 0.8911111111111111\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.25 Penality elasticnet Train Score 0.921156462585034 Test Score 0.8938095238095238\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.35 Penality elasticnet Train Score 0.924625850340136 Test Score 0.893015873015873\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.45 Penality elasticnet Train Score 0.9231292517006803 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.55 Penality elasticnet Train Score 0.9229931972789116 Test Score 0.8949206349206349\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.65 Penality elasticnet Train Score 0.9238775510204081 Test Score 0.8965079365079365\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.75 Penality elasticnet Train Score 0.9242857142857143 Test Score 0.8947619047619048\n",
      "Alpha 0.00012 l1_ratio 0.85 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.85 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.00012 l1_ratio 0.85 Penality elasticnet Train Score 0.9204081632653062 Test Score 0.8917460317460317\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality l1 Train Score 0.9231972789115647 Test Score 0.8946031746031746\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality l2 Train Score 0.9166666666666666 Test Score 0.8884126984126984\n",
      "Alpha 0.00012 l1_ratio 0.95 Penality elasticnet Train Score 0.9236054421768708 Test Score 0.8958730158730158\n"
     ]
    }
   ],
   "source": [
    "for i in ParameterGrid({'alpha':[0.00005,0.00008,0.0001,0.00012],\n",
    "                    'l1_ratio':[0,0.03,0.05,0.08,0.1,0.15,0.25,0.35,\n",
    "                                   0.45,0.55,0.65,0.75,0.85,0.95],\n",
    "                    'penality':['l1','l2','elasticnet']}):\n",
    "    model = SGDClassifier(penalty=i['penality'],alpha=i['alpha'],\n",
    "                          l1_ratio=i['l1_ratio'],random_state=25)\n",
    "    model.fit(X_train_sc,X_train.Score)\n",
    "    train_score = model.score(X_train_sc,X_train.Score)\n",
    "    test_score = model.score(X_test_cv_sc,X_test_cv.Score)\n",
    "    print('Alpha',i['alpha'],'l1_ratio',i['l1_ratio'],'Penality',i['penality'],\n",
    "          'Train Score',train_score,'Test Score',test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random_tfidfw2v = RandomizedSearchCV(\n",
    "                    make_pipeline(TfidfWeightedWord2Vec(w2v_model_300),\n",
    "                    StandardScaler(),SGDClassifier(n_jobs=-1)),\n",
    "                    param_distributions={'sgdclassifier__penalty':['l1','l2'],\n",
    "                    'sgdclassifier__alpha':uniform(loc=0.00001,scale=0.0049),\n",
    "                    'sgdclassifier__l1_ratio':uniform(loc=0,scale=1)},n_iter=40,\n",
    "                      cv=TimeSeriesSplit(n_splits=10),n_jobs=-1) \n",
    "model_random_tfidfw2v.fit(train_df[['final_text','HelpfulnessNumerator',\n",
    "                                'HelpfulnessDenominator']].values,train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = []\n",
    "idx = 0\n",
    "for i in model_random_tfidfw2v.grid_scores_:\n",
    "    dict_score = []\n",
    "    dict_score.append(i[0]['sgdclassifier__alpha'])\n",
    "    dict_score.append(i[0]['sgdclassifier__l1_ratio'])\n",
    "    dict_score.append(i[0]['sgdclassifier__penalty'])\n",
    "    dict_score.append(i[1])\n",
    "    dict_score.append(i[2].std())\n",
    "    dict_score.append(model_random_tfidfw2v.cv_results_['mean_train_score'][idx])\n",
    "    dict_scores.append(dict_score)\n",
    "    idx = idx + 1\n",
    "scores_df = pd.DataFrame(dict_scores,columns=['alpha','l1_ratio','penalty','Test_score',\n",
    "                                               'Test_std','Train_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>penalty</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Test_std</th>\n",
       "      <th>Train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.464483</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.892981</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.924661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.864083</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.892823</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.926553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.891881</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.924244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.995435</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.891828</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.928939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.480030</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.891671</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.924880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.360432</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>0.926045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.521241</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.891409</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.927267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.692168</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.891252</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.926134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.842079</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.891200</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>0.925755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.884751</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.890676</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.924619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha  l1_ratio penalty  Test_score  Test_std  Train_score\n",
       "25  0.000823  0.464483      l1    0.892981  0.008003     0.924661\n",
       "16  0.000456  0.864083      l1    0.892823  0.007788     0.926553\n",
       "29  0.000856  0.372678      l1    0.891881  0.008156     0.924244\n",
       "36  0.000393  0.995435      l1    0.891828  0.007841     0.928939\n",
       "31  0.000906  0.480030      l1    0.891671  0.005621     0.924880\n",
       "37  0.000734  0.360432      l1    0.891566  0.007266     0.926045\n",
       "15  0.000525  0.521241      l1    0.891409  0.008473     0.927267\n",
       "19  0.000608  0.692168      l1    0.891252  0.007907     0.926134\n",
       "4   0.000154  0.842079      l2    0.891200  0.007756     0.925755\n",
       "14  0.000231  0.884751      l2    0.890676  0.006560     0.924619"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values('Test_score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got best cv scores at alpha = 0.000823\tl1_ratio = 0.464483\tpenalty = l1 and mean cv score is 0.892981."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty='l1',alpha=0.000823,l1_ratio=0.464483\n",
      "Train Score 0.9137142857142857\n",
      "Test Score 0.889\n",
      "Test Precision 0.9022622172228472\n",
      "Test Recall 0.9708176438945669\n",
      "Test ConfusionMatrix [[ 782  782]\n",
      " [ 217 7219]]\n"
     ]
    }
   ],
   "source": [
    "#testscore\n",
    "#transforming to tfidf weighted word2vec\n",
    "tfidfvect_w2v = TfidfWeightedWord2Vec(w2v_model_300)\n",
    "tfidfvect_w2v.fit(train_df[['final_text','HelpfulnessNumerator',\n",
    "                           'HelpfulnessDenominator']].values)\n",
    "X_train_tfw2v = tfidfvect_w2v.transform(train_df[['final_text',\n",
    "                'HelpfulnessNumerator','HelpfulnessDenominator']].values)\n",
    "X_cv_tfw2v = tfidfvect_w2v.transform(test_df[['final_text',\n",
    "                 'HelpfulnessNumerator','HelpfulnessDenominator']].values)\n",
    "\n",
    "#scaling the data\n",
    "scale = StandardScaler()\n",
    "X_train_sc = scale.fit_transform(X_train_tfw2v)\n",
    "X_test_cv_sc = scale.transform(X_cv_tfw2v)\n",
    "\n",
    "model = SGDClassifier(penalty='l1',alpha=0.000823,l1_ratio=0.464483,random_state=25)\n",
    "model.fit(X_train_sc,train_df.Score)\n",
    "#Predicting training data\n",
    "train_list = model.predict(X_train_sc)\n",
    "#Accuracy score\n",
    "score_train = accuracy_score(train_df.Score,train_list)\n",
    "#predict test cv\n",
    "test_list = model.predict(X_test_cv_sc)\n",
    "#Accuracy score\n",
    "score_test = accuracy_score(test_df.Score,test_list)\n",
    "#precision\n",
    "#precision\n",
    "test_precision = precision_score(test_df.Score,test_list)\n",
    "#recall\n",
    "test_recall = recall_score(test_df.Score,test_list)\n",
    "#confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(test_df.Score,test_list)\n",
    "print(\"penalty='l1',alpha=0.000823,l1_ratio=0.464483\")\n",
    "print('Train Score', score_train)\n",
    "print('Test Score',score_test)\n",
    "print('Test Precision',test_precision)\n",
    "print('Test Recall',test_recall)\n",
    "print('Test ConfusionMatrix',confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:<br>\n",
    "1. For Binary Bag of Words got high mean cv at `gamma = 0.010 ,C = 7.0` and cv mean score is `0.921215`\n",
    "    *  Train Score `0.9915238095238095`\n",
    "    *  Test Score `0.9246666666666666`\n",
    "    *  Test Precision `0.9447222953408791`\n",
    "    *  Test Recall `0.9653039268423884`\n",
    "    *  No of support vectors for each class `[2245, 3591]`\n",
    "    * Test Confusion Matrix\n",
    "    \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 1144 & 420 &  \\\\\n",
    "    & 258 & 7287 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "<br>\n",
    "2. SGD: For Binary bagof words wit SGD got best cv score at `alpha = 0.003570, l1_ratio = 0.912537, penalty l2` and corresponding mean cv test score is `0.915977`\n",
    "    *  Train Score `0.9445238095238095`\n",
    "    *  Test Score `0.9197777777777778`\n",
    "    *  Test Precision `0.930053804765565`\n",
    "    *  Test Recall `0.9763313609467456`\n",
    "    *  Test Confusion Matrix\n",
    "    \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 1018 & 546 &  \\\\\n",
    "    & 176 & 7260 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "<br>\n",
    "3. For Tf-Idf got high mean cv at `gamma  = 0.175194, C = 7.107109` and mean cv is `0.924987`\n",
    "    *  Train Score `1.0`\n",
    "    *  Test Score `0.9415555555555556`\n",
    "    *  Test Precision `0.9508089770354906`\n",
    "    *  Test Recall `0.9799623453469607`\n",
    "    *  No of support vectors for each class `[2810 6720]`\n",
    "    *  Test Confusion Matrix\n",
    "    \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 1187 & 377 &  \\\\\n",
    "    & 149 & 7287 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "<br>\n",
    "4. SGD: For Tf-Idf with sgd got best scores at `alpha = 0.00003, l1_ratio = 0.15, penalty = l1` and mean cv score is `0.929282`\n",
    "    *  Train Score `0.9569047619047619`\n",
    "    *  Test Score `0.9355555555555556`\n",
    "    *  Test Precision `0.9517659462308908`\n",
    "    *  Test Recall `0.9712210866057019`\n",
    "    *  Test Confusion Matrix \n",
    "    \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 1198 & 366 &  \\\\\n",
    "    & 214 & 7222 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "<br>\n",
    "5. For Avg Word2Vec got high mean cv at `gamma = 0.00100, C = 10` and mean cv score is `0.933630`\n",
    "    *  Train Score `0.9725714285714285`\n",
    "    *  Test Score `0.9332222222222222`\n",
    "    *  Test Precision `0.9459741615555266`\n",
    "    *  Test Recall `0.9748520710059172`\n",
    "    *  No of support vectors for each class `[1693 2078]`\n",
    "    \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 1150 & 414 &  \\\\\n",
    "    & 187 & 7249 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "<br>\n",
    "6. SGD: For Avg Word2Vec got best cv mean score at `alpha = 0.00012,l1_ratio= 0.25 penlty = l1` and mean cv score is `0.925406`\n",
    "    *  Train Score `0.9392380952380952`\n",
    "    *  Test Score `0.9287777777777778`\n",
    "    *  Test Precision `0.9474516001580403`\n",
    "    *  Test Recall `0.9674556213017751`\n",
    "    *  Test ConfusionMatrix\n",
    "    \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 1165 & 399 &  \\\\\n",
    "    & 242 & 7194 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "<br>\n",
    "7. For Tf-Idf Word2Vec got high mean cv at `gamma = 0.00100 C = 20.0` and mean cv score is `0.892457`\n",
    "    *  Train Score `0.9643809523809523`\n",
    "    *  Test Score `0.8904444444444445`\n",
    "    *  Test Precision `0.8969719350073855`\n",
    "    *  Test Recall `0.9799623453469607`\n",
    "    *  No of support vectors for each class `[2031 2750]`\n",
    "    \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 727 & 837 &  \\\\\n",
    "    & 149 & 7287 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}  \n",
    "<br>\n",
    "8. SGD : Got best cv scores at `alpha = 0.000823 l1_ratio = 0.464483 penalty = l1` and mean cv score is `0.892981`.\n",
    "    *  Train Score `0.9137142857142857`\n",
    "    *  Test Score `0.889`\n",
    "    *  Test Precision `0.9022622172228472`\n",
    "    *  Test Recall `0.9708176438945669`\n",
    "    *  Test ConfusionMatrix \n",
    "     \\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    & 782 & 782 &  \\\\\n",
    "    & 217 & 7219 & \n",
    "    \\end{bmatrix}\n",
    "    \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
